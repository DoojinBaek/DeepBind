{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "using gpu :  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import math \n",
    "import random\n",
    "\n",
    "from os import path\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import seq2pad, dinuc_shuffle, complement, reverse_complement, datasets, logsampler, sqrtsampler\n",
    "from Chip import Chip, chipseq_dataset, data_loader, Chip_test\n",
    "from network import ConvNet, ConvNet_test\n",
    "\n",
    "print(torch.__version__)\n",
    "print('using gpu : ', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "num_motif = 16\n",
    "bases = 'ACGT' # DNA bases\n",
    "# basesRNA = 'ACGU' # RNA bases\n",
    "dictReverse = {'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
    "reverse_mode=False\n",
    "# Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Hyperparameters\n",
    "epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "# dataset\n",
    "path = './data/encode/'\n",
    "dataset_names = datasets(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipseq = Chip(dataset_names[0][2]) # './data/encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz'\n",
    "\n",
    "train1, valid1, train2, valid2, train3, valid3, all_data = chipseq.openFile()\n",
    "train_data_loader, valid_data_loader, all_data_loader = data_loader(train1, valid1, train2, valid2, train3, valid3, all_data, batch_size, reverse_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  with Training Fold  1  & learning steps  4000  - AUC :  0.8673213309566251\n",
      "Epoch 1  with Training Fold  1  & learning steps  8000  - AUC :  0.8569152703505645\n",
      "Epoch 1  with Training Fold  1  & learning steps  12000  - AUC :  0.8592957813428401\n",
      "Epoch 1  with Training Fold  1  & learning steps  16000  - AUC :  0.8396619132501486\n",
      "Epoch 1  with Training Fold  1  & learning steps  20000  - AUC :  0.8437346405228758\n",
      "Epoch 1  with Training Fold  2  & learning steps  4000  - AUC :  0.796172192513369\n",
      "Epoch 1  with Training Fold  2  & learning steps  8000  - AUC :  0.7913692216280451\n",
      "Epoch 1  with Training Fold  2  & learning steps  12000  - AUC :  0.7915752822341057\n",
      "Epoch 1  with Training Fold  2  & learning steps  16000  - AUC :  0.788465834818776\n",
      "Epoch 1  with Training Fold  2  & learning steps  20000  - AUC :  0.7798823529411765\n",
      "Epoch 1  with Training Fold  3  & learning steps  4000  - AUC :  0.7550716049382716\n",
      "Epoch 1  with Training Fold  3  & learning steps  8000  - AUC :  0.7534463326071169\n",
      "Epoch 1  with Training Fold  3  & learning steps  12000  - AUC :  0.7469830065359478\n",
      "Epoch 1  with Training Fold  3  & learning steps  16000  - AUC :  0.7391964415395789\n",
      "Epoch 1  with Training Fold  3  & learning steps  20000  - AUC :  0.7324774146695716\n",
      "---------------\n",
      "Epoch 2  with Training Fold  1  & learning steps  4000  - AUC :  0.8588112893642306\n",
      "Epoch 2  with Training Fold  1  & learning steps  8000  - AUC :  0.8579755199049316\n",
      "Epoch 2  with Training Fold  1  & learning steps  12000  - AUC :  0.8666448009506833\n",
      "Epoch 2  with Training Fold  1  & learning steps  16000  - AUC :  0.8584269756387403\n",
      "Epoch 2  with Training Fold  1  & learning steps  20000  - AUC :  0.8559540106951872\n",
      "Epoch 2  with Training Fold  2  & learning steps  4000  - AUC :  0.7985508021390375\n",
      "Epoch 2  with Training Fold  2  & learning steps  8000  - AUC :  0.7967714795008912\n",
      "Epoch 2  with Training Fold  2  & learning steps  12000  - AUC :  0.7901147950089127\n",
      "Epoch 2  with Training Fold  2  & learning steps  16000  - AUC :  0.785092275698158\n",
      "Epoch 2  with Training Fold  2  & learning steps  20000  - AUC :  0.7792178253119431\n",
      "Epoch 2  with Training Fold  3  & learning steps  4000  - AUC :  0.779121568627451\n",
      "Epoch 2  with Training Fold  3  & learning steps  8000  - AUC :  0.7753233115468409\n",
      "Epoch 2  with Training Fold  3  & learning steps  12000  - AUC :  0.7677677559912854\n",
      "Epoch 2  with Training Fold  3  & learning steps  16000  - AUC :  0.763559767610748\n",
      "Epoch 2  with Training Fold  3  & learning steps  20000  - AUC :  0.7549190994916486\n",
      "---------------\n",
      "Epoch 3  with Training Fold  1  & learning steps  4000  - AUC :  0.8272396910279263\n",
      "Epoch 3  with Training Fold  1  & learning steps  8000  - AUC :  0.8106823529411765\n",
      "Epoch 3  with Training Fold  1  & learning steps  12000  - AUC :  0.8006207367795602\n",
      "Epoch 3  with Training Fold  1  & learning steps  16000  - AUC :  0.797427926322044\n",
      "Epoch 3  with Training Fold  1  & learning steps  20000  - AUC :  0.790808734402852\n",
      "Epoch 3  with Training Fold  2  & learning steps  4000  - AUC :  0.8132326797385622\n",
      "Epoch 3  with Training Fold  2  & learning steps  8000  - AUC :  0.8094084373143197\n",
      "Epoch 3  with Training Fold  2  & learning steps  12000  - AUC :  0.8087364230540701\n",
      "Epoch 3  with Training Fold  2  & learning steps  16000  - AUC :  0.8106287581699346\n",
      "Epoch 3  with Training Fold  2  & learning steps  20000  - AUC :  0.8073409387997623\n",
      "Epoch 3  with Training Fold  3  & learning steps  4000  - AUC :  0.7714181554103122\n",
      "Epoch 3  with Training Fold  3  & learning steps  8000  - AUC :  0.7796409586056645\n",
      "Epoch 3  with Training Fold  3  & learning steps  12000  - AUC :  0.7873880900508352\n",
      "Epoch 3  with Training Fold  3  & learning steps  16000  - AUC :  0.7893812636165577\n",
      "Epoch 3  with Training Fold  3  & learning steps  20000  - AUC :  0.7910151053013799\n",
      "---------------\n",
      "Epoch 4  with Training Fold  1  & learning steps  4000  - AUC :  0.8575982174688058\n",
      "Epoch 4  with Training Fold  1  & learning steps  8000  - AUC :  0.843086274509804\n",
      "Epoch 4  with Training Fold  1  & learning steps  12000  - AUC :  0.8506944147355912\n",
      "Epoch 4  with Training Fold  1  & learning steps  16000  - AUC :  0.8376606654783125\n",
      "Epoch 4  with Training Fold  1  & learning steps  20000  - AUC :  0.8426295306001188\n",
      "Epoch 4  with Training Fold  2  & learning steps  4000  - AUC :  0.7380543077837195\n",
      "Epoch 4  with Training Fold  2  & learning steps  8000  - AUC :  0.7327049316696376\n",
      "Epoch 4  with Training Fold  2  & learning steps  12000  - AUC :  0.7292286393345216\n",
      "Epoch 4  with Training Fold  2  & learning steps  16000  - AUC :  0.7313561497326203\n",
      "Epoch 4  with Training Fold  2  & learning steps  20000  - AUC :  0.7269176470588236\n",
      "Epoch 4  with Training Fold  3  & learning steps  4000  - AUC :  0.7582852578068264\n",
      "Epoch 4  with Training Fold  3  & learning steps  8000  - AUC :  0.7392801742919389\n",
      "Epoch 4  with Training Fold  3  & learning steps  12000  - AUC :  0.7423283224400872\n",
      "Epoch 4  with Training Fold  3  & learning steps  16000  - AUC :  0.7380656499636891\n",
      "Epoch 4  with Training Fold  3  & learning steps  20000  - AUC :  0.735529702251271\n",
      "---------------\n",
      "Epoch 5  with Training Fold  1  & learning steps  4000  - AUC :  0.7216956625074272\n",
      "Epoch 5  with Training Fold  1  & learning steps  8000  - AUC :  0.7464487225193106\n",
      "Epoch 5  with Training Fold  1  & learning steps  12000  - AUC :  0.8073837195484254\n",
      "Epoch 5  with Training Fold  1  & learning steps  16000  - AUC :  0.8778187759952466\n",
      "Epoch 5  with Training Fold  1  & learning steps  20000  - AUC :  0.8837764705882353\n",
      "Epoch 5  with Training Fold  2  & learning steps  4000  - AUC :  0.6659881164587047\n",
      "Epoch 5  with Training Fold  2  & learning steps  8000  - AUC :  0.7091290552584669\n",
      "Epoch 5  with Training Fold  2  & learning steps  12000  - AUC :  0.7595426024955437\n",
      "Epoch 5  with Training Fold  2  & learning steps  16000  - AUC :  0.7836117647058823\n",
      "Epoch 5  with Training Fold  2  & learning steps  20000  - AUC :  0.7797850267379678\n",
      "Epoch 5  with Training Fold  3  & learning steps  4000  - AUC :  0.7229826434277415\n",
      "Epoch 5  with Training Fold  3  & learning steps  8000  - AUC :  0.7634111837327524\n",
      "Epoch 5  with Training Fold  3  & learning steps  12000  - AUC :  0.7568082062454611\n",
      "Epoch 5  with Training Fold  3  & learning steps  16000  - AUC :  0.7588928104575164\n",
      "Epoch 5  with Training Fold  3  & learning steps  20000  - AUC :  0.7545684822076979\n",
      "---------------\n",
      "best_poolType= max\n",
      "best_neuType= hidden\n",
      "best_AUC= 0.8121612200435729\n",
      "best_learning_steps= 4000\n",
      "best_LearningRate= 0.008432965656873464\n",
      "best_LearningMomentum= 0.9682263727297178\n",
      "best_sigmaConv= 1.3319097785204658e-07\n",
      "best_dropprob= 0.75\n",
      "best_sigmaNeu= 0.00012289409575888153\n",
      "best_beta1= 9.187167027596117e-14\n",
      "best_beta2= 6.799463342303117e-07\n",
      "best_beta3= 1.5215724162379228e-10\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Learning\n",
    "\n",
    "AUC_best = 0\n",
    "learning_steps_list = [4000, 8000, 12000, 16000, 20000]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pool_list = ['max', 'maxavg']\n",
    "    random_pool = random.choice(pool_list)\n",
    "\n",
    "    neuType_list = ['hidden', 'nohidden']\n",
    "    random_neuType = random.choice(neuType_list)\n",
    "\n",
    "    dropout_list = [0.5, 0.75, 1.0]\n",
    "    drop_rate = random.choice(dropout_list)\n",
    "\n",
    "    lr = logsampler(0.0005, 0.05)\n",
    "    momentum_rate = sqrtsampler(0.95, 0.99)\n",
    "    sigmaConv = logsampler(10**-7, 10**-3)\n",
    "    sigmaNeu=logsampler(10**-5,10**-2) \n",
    "    beta1=logsampler(10**-15,10**-3)\n",
    "    beta2=logsampler(10**-10,10**-3)\n",
    "    beta3=logsampler(10**-10,10**-3)\n",
    "\n",
    "    model_AUC = [[], [], []]\n",
    "\n",
    "    for idx in range(3):\n",
    "        model  = ConvNet(16, 24, random_pool, random_neuType, 'training', drop_rate, lr, momentum_rate, sigmaConv, sigmaNeu, beta1, beta2, beta3, device, reverse_complement_mode=reverse_mode).to(device)\n",
    "        if random_neuType == 'nohidden':\n",
    "            optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias], lr = model.lr, momentum=model.momentum_rate, nesterov=True)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias, model.wHidden, model.wHiddenBias], lr = model.lr, momentum=model.momentum_rate, nesterov=True)\n",
    "        \n",
    "        train_loader = train_data_loader[idx]\n",
    "        valid_loader = valid_data_loader[idx]\n",
    "\n",
    "        learning_steps = 0\n",
    "        while learning_steps <= 20000:\n",
    "            model.mode = 'training'\n",
    "            auc = []\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                if model.reverse_complement_mode:\n",
    "                    target_2 = torch.randn(int(target.shape[0]/2), 1) # 뭐하는 부분인지 이해 안됨!! -> target.shape[0] = 64\n",
    "                    for i in range(target_2.shape[0]):\n",
    "                        target_2[i] = target[2*i]\n",
    "                    target = target_2.to(device)\n",
    "                \n",
    "                # Forward Pass\n",
    "                output = model(data)\n",
    "                if model.neuType == 'nohidden':\n",
    "                    loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta3*model.wNeu.norm()\n",
    "                else: \n",
    "                    loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta2*model.wHidden.norm() + model.beta3*model.wNeu.norm()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                learning_steps+=1\n",
    "\n",
    "                if learning_steps%4000 == 0:\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        model.mode = 'test'\n",
    "                        auc = []\n",
    "                        for i, (data, target) in enumerate(valid_loader):\n",
    "                            data = data.to(device)\n",
    "                            target = target.to(device)\n",
    "                            if model.reverse_complement_mode:\n",
    "                                target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                                for i in range(target_2.shape[0]):\n",
    "                                    target_2[i] = target[2*i]\n",
    "                                target = target_2.to(device)\n",
    "                            # Forward Pass\n",
    "                            output = model(data)\n",
    "                            pred_sig = torch.sigmoid(output)\n",
    "                            pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "                            labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "                        model_AUC[idx].append(np.mean(auc))\n",
    "                        print(\"Epoch\", epoch+1, \" with Training Fold \", idx+1, \" & learning steps \", learning_steps_list[len(model_AUC[idx])-1], \" - AUC : \", np.mean(auc))\n",
    "    \n",
    "    print('---'*5)\n",
    "    for n in range(5):\n",
    "        AUC = (model_AUC[0][n] + model_AUC[1][n] + model_AUC[2][n])/3\n",
    "        if (AUC > AUC_best):\n",
    "            AUC_best = AUC\n",
    "            best_learning_steps = learning_steps_list[n]\n",
    "            best_lr = model.lr\n",
    "            best_momentum = model.momentum_rate\n",
    "            best_neuType = model.neuType\n",
    "            best_poolType = model.poolType\n",
    "            best_sigmaConv = model.sigmaConv\n",
    "            best_droprate = model.droprate\n",
    "            best_sigmaNeu = model.sigmaNeu\n",
    "            best_beta1 = model.beta1\n",
    "            best_beta2 = model.beta2\n",
    "            best_beta3 = model.beta3\n",
    "\n",
    "print('best_poolType=',best_poolType)\n",
    "print('best_neuType=',best_neuType)\n",
    "print('best_AUC=',AUC_best)\n",
    "print('best_learning_steps=',best_learning_steps)      \n",
    "print('best_LearningRate=',best_lr)\n",
    "print('best_LearningMomentum=',best_momentum)\n",
    "print('best_sigmaConv=',best_sigmaConv)\n",
    "print('best_dropprob=',best_droprate)\n",
    "print('best_sigmaNeu=',best_sigmaNeu)\n",
    "print('best_beta1=',best_beta1)\n",
    "print('best_beta2=',best_beta2)\n",
    "print('best_beta3=',best_beta3)\n",
    "\n",
    "best_hyperparameters = {'best_poolType': best_poolType,'best_neuType':best_neuType,'best_learning_steps':best_learning_steps,'best_LearningRate':best_lr,\n",
    "                        'best_LearningMomentum':best_momentum,'best_sigmaConv':best_sigmaConv,'best_dropprob':best_droprate,\n",
    "                        'best_sigmaNeu':best_sigmaNeu,'best_beta1':best_beta1, 'best_beta2':best_beta2,'best_beta3':best_beta3}\n",
    "\n",
    "# Save Hyperparameters\n",
    "name = dataset_names[0][2]\n",
    "name = name.split(path)[1].split(\"_AC\")[0]\n",
    "torch.save(best_hyperparameters, './Hyperparameters/'+name+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for model  0  =  0.7906713345545833\n",
      "AUC for model  1  =  0.769141474998304\n",
      "AUC for model  2  =  0.8489708121310807\n",
      "AUC for model  3  =  0.7422283058552138\n",
      "AUC for model  4  =  0.8665966076395958\n",
      "AUC for model  5  =  0.8596703439853448\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "AUC_best = 0\n",
    "learning_steps_list=[4000,8000,12000,16000,20000]\n",
    "\n",
    "best_hyperparameters = torch.load('./Hyperparameters/'+name+'.pth')\n",
    "\n",
    "best_poolType=best_hyperparameters['best_poolType']\n",
    "best_neuType=best_hyperparameters['best_neuType']\n",
    "best_learning_steps=best_hyperparameters['best_learning_steps']\n",
    "best_lr=best_hyperparameters['best_LearningRate']\n",
    "best_droprate=best_hyperparameters['best_dropprob']\n",
    "best_momentum=best_hyperparameters['best_LearningMomentum']\n",
    "best_sigmaConv=best_hyperparameters['best_sigmaConv']\n",
    "best_sigmaNeu=best_hyperparameters['best_sigmaNeu']\n",
    "best_beta1=best_hyperparameters['best_beta1']\n",
    "best_beta2=best_hyperparameters['best_beta2']\n",
    "best_beta3=best_hyperparameters['best_beta3']\n",
    "\n",
    "for number_models in range(6):\n",
    "    model = ConvNet_test(16, 24, best_poolType, best_neuType, 'training', best_lr, best_momentum, best_sigmaConv, best_droprate, best_sigmaNeu, best_beta1, best_beta2, best_beta3, device, False).to(device)\n",
    "\n",
    "    if model.neuType == 'nohidden':\n",
    "        optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias], lr = model.learning_rate, momentum= model.momentum_rate, nesterov=True)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias, model.wHidden, model.wHiddenBias], lr = model.learning_rate, momentum=model.momentum_rate, nesterov=True)\n",
    "    \n",
    "    train_loader = all_data_loader\n",
    "    valid_loader = all_data_loader\n",
    "    learning_steps = 0\n",
    "\n",
    "    while learning_steps <= best_learning_steps:\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            if reverse_mode:\n",
    "                target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i] = target[2*i]\n",
    "                target = target_2.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            output = model(data)\n",
    "            if model.neuType == 'nohidden':\n",
    "                loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta3*model.wNeu.norm()\n",
    "            else: \n",
    "                loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta2*model.wHidden.norm() + model.beta3*model.wNeu.norm()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            learning_steps += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.mode = 'test'\n",
    "        auc = []\n",
    "        for i, (data, target) in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            if reverse_mode:\n",
    "                target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i] = target[2*i]\n",
    "                target = target_2.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            output = model(data)\n",
    "            pred_sig = torch.sigmoid(output)\n",
    "            pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "            labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "        \n",
    "        AUC_training = np.mean(auc)\n",
    "        print('AUC for model ', number_models, ' = ', AUC_training)\n",
    "        if AUC_training > AUC_best:\n",
    "            state = {'conv': model.wConv,'rect':model.wRect,'wHidden':model.wHidden,'wHiddenBias':model.wHiddenBias,'wNeu':model.wNeu,'wNeuBias':model.wNeuBias}\n",
    "            # Save Models\n",
    "            torch.save(state, './Models/'+name+'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8596703439853448\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./Models/'+name+'.pth')\n",
    "model = ConvNet_test(16, 24, best_poolType, best_neuType, 'test', best_lr, best_momentum, best_sigmaConv, best_droprate, best_sigmaNeu, best_beta1, best_beta2, best_beta3, device, reverse_mode).to(device)\n",
    "model.wConv=checkpoint['conv']\n",
    "model.wRect=checkpoint['rect']\n",
    "model.wHidden=checkpoint['wHidden']\n",
    "model.wHiddenBias=checkpoint['wHiddenBias']\n",
    "model.wNeu=checkpoint['wNeu']\n",
    "model.wNeuBias=checkpoint['wNeuBias']\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.mode = 'test'\n",
    "    auc = []\n",
    "\n",
    "    for i, (data, target) in enumerate(valid_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        if reverse_mode:\n",
    "            target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "            for i in range(target_2.shape[0]):\n",
    "                target_2[i] = target[2*i]\n",
    "            target = target_2.to(device)\n",
    "        \n",
    "        # Forward Pass\n",
    "        output = model(data)\n",
    "        pred_sig = torch.sigmoid(output)\n",
    "        pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "        labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "        auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "    AUC_training = np.mean(auc)\n",
    "    print(AUC_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data =  0.8637\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "chipseq_test=Chip_test(dataset_names[1][2])\n",
    "test_data=chipseq_test.openFile()\n",
    "test_dataset=chipseq_dataset(test_data)\n",
    "batchSize=test_dataset.__len__()\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batchSize,shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "      model.mode='test'\n",
    "      auc=[]\n",
    "     \n",
    "      for i, (data, target) in enumerate(test_loader):\n",
    "          data = data.to(device)\n",
    "          target = target.to(device)\n",
    "          if reverse_mode:\n",
    "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
    "              for i in range(target_2.shape[0]):\n",
    "                target_2[i]=target[2*i]\n",
    "              target=target_2.to(device)\n",
    "          # Forward pass\n",
    "          output = model(data)\n",
    "          pred_sig=torch.sigmoid(output)\n",
    "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "          \n",
    "          auc.append(metrics.roc_auc_score(labels, pred))\n",
    "            \n",
    "      AUC_training=np.mean(auc)\n",
    "      print('AUC on test data = ',AUC_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
