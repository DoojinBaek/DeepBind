{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "using gpu :  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from os import path\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import datasets, logsampler, sqrtsampler\n",
    "from Chip import Chip, chipseq_dataset, data_loader, Chip_test\n",
    "from network import ConvNet, ConvNet_test\n",
    "\n",
    "print(torch.__version__)\n",
    "print('using gpu : ', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "num_motif = 16 # number of motif detectors (filter)\n",
    "reverse_mode=False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_grid_search = 5 # too small\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "\n",
    "# dataset\n",
    "path = './data/encode/'\n",
    "dataset_names = datasets(path)\n",
    "num_tf = len(dataset_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipseq = Chip(dataset_names[0][2]) # './data/encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz'\n",
    "\n",
    "train1, valid1, train2, valid2, train3, valid3, all_data = chipseq.openFile()\n",
    "train_data_loader, valid_data_loader, all_data_loader = data_loader(train1, valid1, train2, valid2, train3, valid3, all_data, batch_size, reverse_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid 1  with Training Fold  1  & learning steps  4000  - AUC :  0.888779952671688\n",
      "Grid 1  with Training Fold  1  & learning steps  8000  - AUC :  0.9006403230561473\n",
      "Grid 1  with Training Fold  1  & learning steps  12000  - AUC :  0.8940734206989247\n",
      "Grid 1  with Training Fold  1  & learning steps  16000  - AUC :  0.8966494931147291\n",
      "Grid 1  with Training Fold  1  & learning steps  20000  - AUC :  0.892409519869649\n",
      "Grid 1  with Training Fold  2  & learning steps  4000  - AUC :  0.7565356777173362\n",
      "Grid 1  with Training Fold  2  & learning steps  8000  - AUC :  0.7408047398052344\n",
      "Grid 1  with Training Fold  2  & learning steps  12000  - AUC :  0.7579441744649017\n",
      "Grid 1  with Training Fold  2  & learning steps  16000  - AUC :  0.7587816525918035\n",
      "Grid 1  with Training Fold  2  & learning steps  20000  - AUC :  0.7587324579339115\n",
      "Grid 1  with Training Fold  3  & learning steps  4000  - AUC :  0.757071148079953\n",
      "Grid 1  with Training Fold  3  & learning steps  8000  - AUC :  0.7590235157277698\n",
      "Grid 1  with Training Fold  3  & learning steps  12000  - AUC :  0.7620643710241887\n",
      "Grid 1  with Training Fold  3  & learning steps  16000  - AUC :  0.7593150100376966\n",
      "Grid 1  with Training Fold  3  & learning steps  20000  - AUC :  0.7551311664956903\n",
      "---------------\n",
      "Grid 2  with Training Fold  1  & learning steps  4000  - AUC :  0.9022024862421384\n",
      "Grid 2  with Training Fold  1  & learning steps  8000  - AUC :  0.8982219390342869\n",
      "Grid 2  with Training Fold  1  & learning steps  12000  - AUC :  0.8957644647748022\n",
      "Grid 2  with Training Fold  1  & learning steps  16000  - AUC :  0.9001642859860012\n",
      "Grid 2  with Training Fold  1  & learning steps  20000  - AUC :  0.8960278137046054\n",
      "Grid 2  with Training Fold  2  & learning steps  4000  - AUC :  0.8149427336934469\n",
      "Grid 2  with Training Fold  2  & learning steps  8000  - AUC :  0.8143864358262325\n",
      "Grid 2  with Training Fold  2  & learning steps  12000  - AUC :  0.8054484420965207\n",
      "Grid 2  with Training Fold  2  & learning steps  16000  - AUC :  0.8059432416882227\n",
      "Grid 2  with Training Fold  2  & learning steps  20000  - AUC :  0.8067531010663928\n",
      "Grid 2  with Training Fold  3  & learning steps  4000  - AUC :  0.7685468838964915\n",
      "Grid 2  with Training Fold  3  & learning steps  8000  - AUC :  0.7592805744801995\n",
      "Grid 2  with Training Fold  3  & learning steps  12000  - AUC :  0.7556461851537805\n",
      "Grid 2  with Training Fold  3  & learning steps  16000  - AUC :  0.7603885327906269\n",
      "Grid 2  with Training Fold  3  & learning steps  20000  - AUC :  0.7602311569242927\n",
      "---------------\n",
      "Grid 3  with Training Fold  1  & learning steps  4000  - AUC :  0.6980785355168391\n",
      "Grid 3  with Training Fold  1  & learning steps  8000  - AUC :  0.9022759909464394\n",
      "Grid 3  with Training Fold  1  & learning steps  12000  - AUC :  0.8996949257582674\n",
      "Grid 3  with Training Fold  1  & learning steps  16000  - AUC :  0.8964521993558531\n",
      "Grid 3  with Training Fold  1  & learning steps  20000  - AUC :  0.8990946241314162\n",
      "Grid 3  with Training Fold  2  & learning steps  4000  - AUC :  0.7601143661873605\n",
      "Grid 3  with Training Fold  2  & learning steps  8000  - AUC :  0.7902466786176201\n",
      "Grid 3  with Training Fold  2  & learning steps  12000  - AUC :  0.8004929570209474\n",
      "Grid 3  with Training Fold  2  & learning steps  16000  - AUC :  0.7961364461287787\n",
      "Grid 3  with Training Fold  2  & learning steps  20000  - AUC :  0.7964756574609454\n",
      "Grid 3  with Training Fold  3  & learning steps  4000  - AUC :  0.6490371887148312\n",
      "Grid 3  with Training Fold  3  & learning steps  8000  - AUC :  0.7060602094602222\n",
      "Grid 3  with Training Fold  3  & learning steps  12000  - AUC :  0.7423585273791059\n",
      "Grid 3  with Training Fold  3  & learning steps  16000  - AUC :  0.7670406637917706\n",
      "Grid 3  with Training Fold  3  & learning steps  20000  - AUC :  0.7605306561591944\n",
      "---------------\n",
      "Grid 4  with Training Fold  1  & learning steps  4000  - AUC :  0.6947972934418747\n",
      "Grid 4  with Training Fold  1  & learning steps  8000  - AUC :  0.786140499784439\n",
      "Grid 4  with Training Fold  1  & learning steps  12000  - AUC :  0.8148115743558532\n",
      "Grid 4  with Training Fold  1  & learning steps  16000  - AUC :  0.8150239653073645\n",
      "Grid 4  with Training Fold  1  & learning steps  20000  - AUC :  0.8170213912558328\n",
      "Grid 4  with Training Fold  2  & learning steps  4000  - AUC :  0.706679081234784\n",
      "Grid 4  with Training Fold  2  & learning steps  8000  - AUC :  0.7149967626229965\n",
      "Grid 4  with Training Fold  2  & learning steps  12000  - AUC :  0.7436247448138568\n",
      "Grid 4  with Training Fold  2  & learning steps  16000  - AUC :  0.7946080039688578\n",
      "Grid 4  with Training Fold  2  & learning steps  20000  - AUC :  0.8015038151120918\n",
      "Grid 4  with Training Fold  3  & learning steps  4000  - AUC :  0.6342117608856243\n",
      "Grid 4  with Training Fold  3  & learning steps  8000  - AUC :  0.6878000456788821\n",
      "Grid 4  with Training Fold  3  & learning steps  12000  - AUC :  0.7528956162384899\n",
      "Grid 4  with Training Fold  3  & learning steps  16000  - AUC :  0.7512490750716628\n",
      "Grid 4  with Training Fold  3  & learning steps  20000  - AUC :  0.7680013602428681\n",
      "---------------\n",
      "Grid 5  with Training Fold  1  & learning steps  4000  - AUC :  0.8729404021480016\n",
      "Grid 5  with Training Fold  1  & learning steps  8000  - AUC :  0.8754243460260701\n",
      "Grid 5  with Training Fold  1  & learning steps  12000  - AUC :  0.8722661005021303\n",
      "Grid 5  with Training Fold  1  & learning steps  16000  - AUC :  0.8710315780964699\n",
      "Grid 5  with Training Fold  1  & learning steps  20000  - AUC :  0.8658206295014202\n",
      "Grid 5  with Training Fold  2  & learning steps  4000  - AUC :  0.8140601621145263\n",
      "Grid 5  with Training Fold  2  & learning steps  8000  - AUC :  0.8049798149345709\n",
      "Grid 5  with Training Fold  2  & learning steps  12000  - AUC :  0.8050674262020694\n",
      "Grid 5  with Training Fold  2  & learning steps  16000  - AUC :  0.8026832585209982\n",
      "Grid 5  with Training Fold  2  & learning steps  20000  - AUC :  0.7963358994598296\n",
      "Grid 5  with Training Fold  3  & learning steps  4000  - AUC :  0.7862135328213045\n",
      "Grid 5  with Training Fold  3  & learning steps  8000  - AUC :  0.783914249939872\n",
      "Grid 5  with Training Fold  3  & learning steps  12000  - AUC :  0.7828159550598335\n",
      "Grid 5  with Training Fold  3  & learning steps  16000  - AUC :  0.7820774120535802\n",
      "Grid 5  with Training Fold  3  & learning steps  20000  - AUC :  0.779059833353376\n",
      "---------------\n",
      "best_poolType= maxavg\n",
      "best_neuType= nohidden\n",
      "best_AUC= 0.8285640346106922\n",
      "best_learning_steps= 4000\n",
      "best_LearningRate= 0.001895745475667348\n",
      "best_LearningMomentum= 0.9882199458427827\n",
      "best_sigmaConv= 5.080563073219538e-07\n",
      "best_dropprob= 0.5\n",
      "best_sigmaNeu= 0.0013801107961261643\n",
      "best_beta1= 4.549566940478581e-14\n",
      "best_beta2= 1.5028324784112626e-05\n",
      "best_beta3= 0.0002830662192671867\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Learning\n",
    "\n",
    "AUC_best = 0\n",
    "learning_steps_list = [4000, 8000, 12000, 16000, 20000]\n",
    "num_learning_steps = len(learning_steps_list)\n",
    "\n",
    "for grid in range(num_grid_search):\n",
    "    pool_list = ['max', 'maxavg']\n",
    "    random_pool = random.choice(pool_list)\n",
    "\n",
    "    neuType_list = ['hidden', 'nohidden']\n",
    "    random_neuType = random.choice(neuType_list)\n",
    "\n",
    "    dropout_list = [0.25, 0.5 , 0.75]\n",
    "    drop_rate = random.choice(dropout_list)\n",
    "\n",
    "    lr = logsampler(0.0005, 0.05)\n",
    "    momentum_rate = sqrtsampler(0.95, 0.99)\n",
    "    sigmaConv = logsampler(10**-7, 10**-3)\n",
    "    sigmaNeu=logsampler(10**-5,10**-2) \n",
    "    beta1=logsampler(10**-15,10**-3)\n",
    "    beta2=logsampler(10**-10,10**-3)\n",
    "    beta3=logsampler(10**-10,10**-3)\n",
    "\n",
    "    model_AUC = [[], [], []]\n",
    "\n",
    "    for idx in range(3):\n",
    "        model  = ConvNet(16, 24, random_pool, random_neuType, 'training', drop_rate, lr, momentum_rate, sigmaConv, sigmaNeu, beta1, beta2, beta3, device, reverse_complement_mode=reverse_mode).to(device)\n",
    "        if random_neuType == 'nohidden':\n",
    "            optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias], lr = model.lr, momentum=model.momentum_rate, nesterov=True)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias, model.wHidden, model.wHiddenBias], lr = model.lr, momentum=model.momentum_rate, nesterov=True)\n",
    "        \n",
    "        train_loader = train_data_loader[idx]\n",
    "        valid_loader = valid_data_loader[idx]\n",
    "\n",
    "        learning_steps = 0\n",
    "        while learning_steps <= 20000:\n",
    "            model.mode = 'training'\n",
    "            auc = []\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                if model.reverse_complement_mode:\n",
    "                    target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                    for i in range(target_2.shape[0]):\n",
    "                        target_2[i] = target[2*i]\n",
    "                    target = target_2.to(device) # target for main strand, not complemantary strand\n",
    "                \n",
    "                # Forward Pass\n",
    "                output = model(data)\n",
    "                if model.neuType == 'nohidden':\n",
    "                    loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta3*model.wNeu.norm()\n",
    "                else: \n",
    "                    loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta2*model.wHidden.norm() + model.beta3*model.wNeu.norm()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                learning_steps+=1\n",
    "\n",
    "                if learning_steps%4000 == 0:\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        model.mode = 'test'\n",
    "                        auc = []\n",
    "                        for i, (data, target) in enumerate(valid_loader):\n",
    "                            data = data.to(device)\n",
    "                            target = target.to(device)\n",
    "                            if model.reverse_complement_mode:\n",
    "                                target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                                for i in range(target_2.shape[0]):\n",
    "                                    target_2[i] = target[2*i]\n",
    "                                target = target_2.to(device)\n",
    "                            # Forward Pass\n",
    "                            output = model(data)\n",
    "                            pred_sig = torch.sigmoid(output)\n",
    "                            pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "                            labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "                        model_AUC[idx].append(np.mean(auc))\n",
    "                        print(\"Grid\", grid+1, \" with Training Fold \", idx+1, \" & learning steps \", learning_steps_list[len(model_AUC[idx])-1], \" - AUC : \", np.mean(auc))\n",
    "    \n",
    "    print('---'*5)\n",
    "    for n in range(num_learning_steps):\n",
    "        AUC = (model_AUC[0][n] + model_AUC[1][n] + model_AUC[2][n])/3\n",
    "        if (AUC > AUC_best):\n",
    "            AUC_best = AUC\n",
    "            best_learning_steps = learning_steps_list[n]\n",
    "            best_lr = model.lr\n",
    "            best_momentum = model.momentum_rate\n",
    "            best_neuType = model.neuType\n",
    "            best_poolType = model.poolType\n",
    "            best_sigmaConv = model.sigmaConv\n",
    "            best_droprate = model.droprate\n",
    "            best_sigmaNeu = model.sigmaNeu\n",
    "            best_beta1 = model.beta1\n",
    "            best_beta2 = model.beta2\n",
    "            best_beta3 = model.beta3\n",
    "\n",
    "print('best_poolType=',best_poolType)\n",
    "print('best_neuType=',best_neuType)\n",
    "print('best_AUC=',AUC_best)\n",
    "print('best_learning_steps=',best_learning_steps)      \n",
    "print('best_LearningRate=',best_lr)\n",
    "print('best_LearningMomentum=',best_momentum)\n",
    "print('best_sigmaConv=',best_sigmaConv)\n",
    "print('best_dropprob=',best_droprate)\n",
    "print('best_sigmaNeu=',best_sigmaNeu)\n",
    "print('best_beta1=',best_beta1)\n",
    "print('best_beta2=',best_beta2)\n",
    "print('best_beta3=',best_beta3)\n",
    "\n",
    "best_hyperparameters = {'best_poolType': best_poolType,'best_neuType':best_neuType,'best_learning_steps':best_learning_steps,'best_LearningRate':best_lr,\n",
    "                        'best_LearningMomentum':best_momentum,'best_sigmaConv':best_sigmaConv,'best_dropprob':best_droprate,\n",
    "                        'best_sigmaNeu':best_sigmaNeu,'best_beta1':best_beta1, 'best_beta2':best_beta2,'best_beta3':best_beta3}\n",
    "\n",
    "# Save Hyperparameters\n",
    "name = dataset_names[0][2]\n",
    "name = name.split(path)[1].split(\"_AC\")[0]\n",
    "torch.save(best_hyperparameters, './Hyperparameters/'+name+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for model  0  =  0.4758216486771596\n",
      "AUC for model  1  =  0.5055216330341098\n",
      "AUC for model  2  =  0.4768478477770825\n",
      "AUC for model  3  =  0.522295544839398\n",
      "AUC for model  4  =  0.5080940247561289\n",
      "AUC for model  5  =  0.5248154170276601\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "AUC_best = 0\n",
    "learning_steps_list=[4000,8000,12000,16000,20000]\n",
    "\n",
    "best_hyperparameters = torch.load('./Hyperparameters/'+name+'.pth')\n",
    "\n",
    "best_poolType=best_hyperparameters['best_poolType']\n",
    "best_neuType=best_hyperparameters['best_neuType']\n",
    "best_learning_steps=best_hyperparameters['best_learning_steps']\n",
    "best_lr=best_hyperparameters['best_LearningRate']\n",
    "best_droprate=best_hyperparameters['best_dropprob']\n",
    "best_momentum=best_hyperparameters['best_LearningMomentum']\n",
    "best_sigmaConv=best_hyperparameters['best_sigmaConv']\n",
    "best_sigmaNeu=best_hyperparameters['best_sigmaNeu']\n",
    "best_beta1=best_hyperparameters['best_beta1']\n",
    "best_beta2=best_hyperparameters['best_beta2']\n",
    "best_beta3=best_hyperparameters['best_beta3']\n",
    "\n",
    "for number_models in range(6):\n",
    "    model = ConvNet_test(16, 24, best_poolType, best_neuType, 'training', best_lr, best_momentum, best_sigmaConv, best_droprate, best_sigmaNeu, best_beta1, best_beta2, best_beta3, device, False).to(device)\n",
    "\n",
    "    if model.neuType == 'nohidden':\n",
    "        optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias], lr = model.learning_rate, momentum= model.momentum_rate, nesterov=True)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD([model.wConv, model.wRect, model.wNeu, model.wNeuBias, model.wHidden, model.wHiddenBias], lr = model.learning_rate, momentum=model.momentum_rate, nesterov=True)\n",
    "    \n",
    "    train_loader = all_data_loader\n",
    "    valid_loader = all_data_loader\n",
    "    learning_steps = 0\n",
    "\n",
    "    while learning_steps <= best_learning_steps:\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            if reverse_mode:\n",
    "                target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i] = target[2*i]\n",
    "                target = target_2.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            output = model(data)\n",
    "            if model.neuType == 'nohidden':\n",
    "                loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta3*model.wNeu.norm()\n",
    "            else: \n",
    "                loss = F.binary_cross_entropy(torch.sigmoid(output), target) + model.beta1*model.wConv.norm() + model.beta2*model.wHidden.norm() + model.beta3*model.wNeu.norm()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            learning_steps += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.mode = 'test'\n",
    "        auc = []\n",
    "        for i, (data, target) in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            if reverse_mode:\n",
    "                target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i] = target[2*i]\n",
    "                target = target_2.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            output = model(data)\n",
    "            pred_sig = torch.sigmoid(output)\n",
    "            pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "            labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "        \n",
    "        AUC_training = np.mean(auc)\n",
    "        print('AUC for model ', number_models, ' = ', AUC_training)\n",
    "        if AUC_training > AUC_best:\n",
    "            state = {'conv': model.wConv,'rect':model.wRect,'wHidden':model.wHidden,'wHiddenBias':model.wHiddenBias,'wNeu':model.wNeu,'wNeuBias':model.wNeuBias}\n",
    "            # Save Models\n",
    "            torch.save(state, './Models/'+name+'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5248154170276601\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./Models/'+name+'.pth')\n",
    "model = ConvNet_test(16, 24, best_poolType, best_neuType, 'test', best_lr, best_momentum, best_sigmaConv, best_droprate, best_sigmaNeu, best_beta1, best_beta2, best_beta3, device, reverse_mode).to(device)\n",
    "model.wConv=checkpoint['conv']\n",
    "model.wRect=checkpoint['rect']\n",
    "model.wHidden=checkpoint['wHidden']\n",
    "model.wHiddenBias=checkpoint['wHiddenBias']\n",
    "model.wNeu=checkpoint['wNeu']\n",
    "model.wNeuBias=checkpoint['wNeuBias']\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.mode = 'test'\n",
    "    auc = []\n",
    "\n",
    "    for i, (data, target) in enumerate(valid_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        if reverse_mode:\n",
    "            target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "            for i in range(target_2.shape[0]):\n",
    "                target_2[i] = target[2*i]\n",
    "            target = target_2.to(device)\n",
    "        \n",
    "        # Forward Pass\n",
    "        output = model(data)\n",
    "        pred_sig = torch.sigmoid(output)\n",
    "        pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "        labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "        auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "    AUC_training = np.mean(auc)\n",
    "    print(AUC_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data =  0.50047\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "chipseq_test=Chip_test(dataset_names[1][2])\n",
    "test_data=chipseq_test.openFile()\n",
    "test_dataset=chipseq_dataset(test_data)\n",
    "batchSize=test_dataset.__len__()\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batchSize,shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "      model.mode='test'\n",
    "      auc=[]\n",
    "     \n",
    "      for i, (data, target) in enumerate(test_loader):\n",
    "          data = data.to(device)\n",
    "          target = target.to(device)\n",
    "          if reverse_mode:\n",
    "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
    "              for i in range(target_2.shape[0]):\n",
    "                target_2[i]=target[2*i]\n",
    "              target=target_2.to(device)\n",
    "          # Forward pass\n",
    "          output = model(data)\n",
    "          pred_sig=torch.sigmoid(output)\n",
    "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "          \n",
    "          auc.append(metrics.roc_auc_score(labels, pred))\n",
    "            \n",
    "      AUC_test=np.mean(auc)\n",
    "      print('AUC on test data = ',AUC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/AUC_training.txt\", \"a\") as file:\n",
    "    file.write('TF : ')\n",
    "    file.write(name)\n",
    "    file.write(\" - AUC Training : \")\n",
    "    file.write(\"%d\" %AUC_training)\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"---\"*20)\n",
    "    file.write(\"\\n\")\n",
    "file.close()\n",
    "\n",
    "with open(\"./results/AUC_testing.txt\", \"a\") as file:\n",
    "    file.write('TF : ')\n",
    "    file.write(name)\n",
    "    file.write(\" - AUC Test : \")\n",
    "    file.write(\"%d\" %AUC_test)\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"---\"*20)\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
