{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "colab_type": "code",
        "id": "T_Goiz940CV9",
        "outputId": "41f5e88b-c037-41c2-fd7b-5114331fed08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.2\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import metrics\n",
        "from utils import logsampler, sqrtsampler, datasets, dataset_loader, test_dataset_loader\n",
        "from network import ConvNet, ConvNet_test\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9mOZziHBz8FT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./data/encode/FOXA1_HepG2_FOXA1_(SC-101058)_HudsonAlpha_AC.seq.gz\n",
            "./data/encode/FOXA1_HepG2_FOXA1_(SC-101058)_HudsonAlpha_B.seq.gz\n",
            "FOXA1_HepG2_FOXA1_(SC-101058)_HudsonAlpha\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "num_motif = 16 # number of motif detector (filter in CNN)\n",
        "motif_len = 24\n",
        "batch_size = 64\n",
        "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
        "reverse_mode=False\n",
        "num_grid_search = 5 # too small\n",
        "num_training_model = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Settings\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# dataset path\n",
        "\n",
        "path = './data/encode/'\n",
        "all_dataset_names = datasets(path)\n",
        "data_idx = 3 # ELK1_GM12878_ELK1_(1277-1)_Stanford\n",
        "dataset_name = all_dataset_names[data_idx]\n",
        "\n",
        "train_dataset_path = dataset_name[0]\n",
        "test_dataset_path = dataset_name[1]\n",
        "print(train_dataset_path)\n",
        "print(test_dataset_path)\n",
        "\n",
        "name = train_dataset_path.split(path)[1].split(\"_AC\")[0]\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GwYhmKt6z8Fn"
      },
      "outputs": [],
      "source": [
        "train_dataloader, valid_dataloader, all_dataloader = dataset_loader(train_dataset_path, batch_size, reverse_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "colab_type": "code",
        "id": "3_ACNZE2z8GE",
        "outputId": "592d2faf-ecc8-4646-fdf7-a86fc6ee4611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid  1  with training fold  1  & learning steps  4000  showed AUC of  0.9368038747163883\n",
            "Grid  1  with training fold  1  & learning steps  8000  showed AUC of  0.9469327039959449\n",
            "Grid  1  with training fold  1  & learning steps  12000  showed AUC of  0.9491737638962855\n",
            "Grid  1  with training fold  1  & learning steps  16000  showed AUC of  0.9522863970516853\n",
            "Grid  1  with training fold  1  & learning steps  20000  showed AUC of  0.9521899998058404\n",
            "Grid  1  with training fold  2  & learning steps  4000  showed AUC of  0.9502189215366074\n",
            "Grid  1  with training fold  2  & learning steps  8000  showed AUC of  0.9557885413892956\n",
            "Grid  1  with training fold  2  & learning steps  12000  showed AUC of  0.9575618844964885\n",
            "Grid  1  with training fold  2  & learning steps  16000  showed AUC of  0.9587052271252163\n",
            "Grid  1  with training fold  2  & learning steps  20000  showed AUC of  0.9582409937213614\n",
            "Grid  1  with training fold  3  & learning steps  4000  showed AUC of  0.9312817434333858\n",
            "Grid  1  with training fold  3  & learning steps  8000  showed AUC of  0.9364841609640631\n",
            "Grid  1  with training fold  3  & learning steps  12000  showed AUC of  0.9379473753838001\n",
            "Grid  1  with training fold  3  & learning steps  16000  showed AUC of  0.9397233113715305\n",
            "Grid  1  with training fold  3  & learning steps  20000  showed AUC of  0.9406122718707486\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  2  with training fold  1  & learning steps  4000  showed AUC of  0.9725237836936382\n",
            "Grid  2  with training fold  1  & learning steps  8000  showed AUC of  0.9759715806573969\n",
            "Grid  2  with training fold  1  & learning steps  12000  showed AUC of  0.9775373180966527\n",
            "Grid  2  with training fold  1  & learning steps  16000  showed AUC of  0.9782154251022113\n",
            "Grid  2  with training fold  1  & learning steps  20000  showed AUC of  0.9777580338767031\n",
            "Grid  2  with training fold  2  & learning steps  4000  showed AUC of  0.8978572095995319\n",
            "Grid  2  with training fold  2  & learning steps  8000  showed AUC of  0.9147470970527948\n",
            "Grid  2  with training fold  2  & learning steps  12000  showed AUC of  0.9170101516040363\n",
            "Grid  2  with training fold  2  & learning steps  16000  showed AUC of  0.9187968865282308\n",
            "Grid  2  with training fold  2  & learning steps  20000  showed AUC of  0.9175111529132274\n",
            "Grid  2  with training fold  3  & learning steps  4000  showed AUC of  0.9212329784939703\n",
            "Grid  2  with training fold  3  & learning steps  8000  showed AUC of  0.9289420016381386\n",
            "Grid  2  with training fold  3  & learning steps  12000  showed AUC of  0.933550370062486\n",
            "Grid  2  with training fold  3  & learning steps  16000  showed AUC of  0.9370732410053856\n",
            "Grid  2  with training fold  3  & learning steps  20000  showed AUC of  0.9372194544355779\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  3  with training fold  1  & learning steps  4000  showed AUC of  0.5186528508187991\n",
            "Grid  3  with training fold  1  & learning steps  8000  showed AUC of  0.3865526307942795\n",
            "Grid  3  with training fold  1  & learning steps  12000  showed AUC of  0.864447194028619\n",
            "Grid  3  with training fold  1  & learning steps  16000  showed AUC of  0.8837225476419307\n",
            "Grid  3  with training fold  1  & learning steps  20000  showed AUC of  0.9386777214599143\n",
            "Grid  3  with training fold  2  & learning steps  4000  showed AUC of  0.411030353181653\n",
            "Grid  3  with training fold  2  & learning steps  8000  showed AUC of  0.6855014500867478\n",
            "Grid  3  with training fold  2  & learning steps  12000  showed AUC of  0.7872301017968785\n",
            "Grid  3  with training fold  2  & learning steps  16000  showed AUC of  0.9033004848097791\n",
            "Grid  3  with training fold  2  & learning steps  20000  showed AUC of  0.9264412628838814\n",
            "Grid  3  with training fold  3  & learning steps  4000  showed AUC of  0.39737743367020034\n",
            "Grid  3  with training fold  3  & learning steps  8000  showed AUC of  0.7689812934997181\n",
            "Grid  3  with training fold  3  & learning steps  12000  showed AUC of  0.7912186139208471\n",
            "Grid  3  with training fold  3  & learning steps  16000  showed AUC of  0.8755358116644438\n",
            "Grid  3  with training fold  3  & learning steps  20000  showed AUC of  0.9010542907070827\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  4  with training fold  1  & learning steps  4000  showed AUC of  0.9730935535000056\n",
            "Grid  4  with training fold  1  & learning steps  8000  showed AUC of  0.9759115450117606\n",
            "Grid  4  with training fold  1  & learning steps  12000  showed AUC of  0.974691123591649\n",
            "Grid  4  with training fold  1  & learning steps  16000  showed AUC of  0.9768838927732381\n",
            "Grid  4  with training fold  1  & learning steps  20000  showed AUC of  0.9761799664311787\n",
            "Grid  4  with training fold  2  & learning steps  4000  showed AUC of  0.9368601290156381\n",
            "Grid  4  with training fold  2  & learning steps  8000  showed AUC of  0.9416045594066202\n",
            "Grid  4  with training fold  2  & learning steps  12000  showed AUC of  0.9423890587641597\n",
            "Grid  4  with training fold  2  & learning steps  16000  showed AUC of  0.9435618991451427\n",
            "Grid  4  with training fold  2  & learning steps  20000  showed AUC of  0.9433497970337948\n",
            "Grid  4  with training fold  3  & learning steps  4000  showed AUC of  0.9224918257311452\n",
            "Grid  4  with training fold  3  & learning steps  8000  showed AUC of  0.9234318629880438\n",
            "Grid  4  with training fold  3  & learning steps  12000  showed AUC of  0.9257484907851148\n",
            "Grid  4  with training fold  3  & learning steps  16000  showed AUC of  0.925602266893733\n",
            "Grid  4  with training fold  3  & learning steps  20000  showed AUC of  0.9259119128720167\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  5  with training fold  1  & learning steps  4000  showed AUC of  0.9631530005991212\n",
            "Grid  5  with training fold  1  & learning steps  8000  showed AUC of  0.9627992767725391\n",
            "Grid  5  with training fold  1  & learning steps  12000  showed AUC of  0.9612018312811349\n",
            "Grid  5  with training fold  1  & learning steps  16000  showed AUC of  0.9653028314548384\n",
            "Grid  5  with training fold  1  & learning steps  20000  showed AUC of  0.9632126299396302\n",
            "Grid  5  with training fold  2  & learning steps  4000  showed AUC of  0.9158536880283917\n",
            "Grid  5  with training fold  2  & learning steps  8000  showed AUC of  0.9151654504816547\n",
            "Grid  5  with training fold  2  & learning steps  12000  showed AUC of  0.9156552106823187\n",
            "Grid  5  with training fold  2  & learning steps  16000  showed AUC of  0.911947486785007\n",
            "Grid  5  with training fold  2  & learning steps  20000  showed AUC of  0.9147225399708899\n",
            "Grid  5  with training fold  3  & learning steps  4000  showed AUC of  0.9280542533292526\n",
            "Grid  5  with training fold  3  & learning steps  8000  showed AUC of  0.9343096235808769\n",
            "Grid  5  with training fold  3  & learning steps  12000  showed AUC of  0.9337208286069679\n",
            "Grid  5  with training fold  3  & learning steps  16000  showed AUC of  0.9355324346355589\n",
            "Grid  5  with training fold  3  & learning steps  20000  showed AUC of  0.9335070018938101\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Grid Search\n",
        "\n",
        "best_AUC=0\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for grid in range(num_grid_search):\n",
        "    \n",
        "    # randomly select hyperparameters\n",
        "    pool_List=['max','maxavg']        \n",
        "    random_pool=random.choice(pool_List)\n",
        "    neuType_list=['hidden','nohidden']\n",
        "    random_neuType=random.choice(neuType_list)\n",
        "    dropoutList=[0.5,0.75,1.0] \n",
        "    dropprob=random.choice(dropoutList)\n",
        "    learning_rate=logsampler(0.0005,0.05)\n",
        "    momentum_rate=sqrtsampler(0.95,0.99)  \n",
        "    sigmaConv=logsampler(10**-7,10**-3)   \n",
        "    sigmaNeu=logsampler(10**-5,10**-2) \n",
        "    beta1=logsampler(10**-15,10**-3)\n",
        "    beta2=logsampler(10**-10,10**-3)\n",
        "    beta3=logsampler(10**-10,10**-3)\n",
        "\n",
        "    model_auc=[[],[],[]]\n",
        "\n",
        "    for idx in range(3):\n",
        "        model = ConvNet(num_motif,motif_len,random_pool,random_neuType,'training',dropprob,learning_rate,momentum_rate,sigmaConv,sigmaNeu,beta1,beta2,beta3, device, reverse_complemet_mode=reverse_mode).to(device)\n",
        "        if random_neuType=='nohidden':\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        train_loader=train_dataloader[idx]\n",
        "        valid_loader=valid_dataloader[idx]\n",
        "\n",
        "        learning_steps=0\n",
        "\n",
        "        while learning_steps<=20000:\n",
        "            model.mode='training'\n",
        "            auc=[]\n",
        "            for i, (data, target) in enumerate(train_loader):\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "                if model.reverse_complemet_mode:\n",
        "                    target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                    for i in range(target_2.shape[0]):\n",
        "                        target_2[i]=target[2*i]\n",
        "                    target=target_2.to(device)\n",
        "                \n",
        "                # Forward pass\n",
        "                output = model(data)\n",
        "                \n",
        "                if model.neuType=='nohidden':\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "                else:\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                learning_steps+=1\n",
        "    \n",
        "                if learning_steps% 4000==0:\n",
        "                    with torch.no_grad():\n",
        "                        model.mode='test'\n",
        "                        auc=[]\n",
        "                        for i, (data, target) in enumerate(valid_loader):\n",
        "                            data = data.to(device)\n",
        "                            target = target.to(device)\n",
        "                            if model.reverse_complemet_mode:\n",
        "                                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                                for i in range(target_2.shape[0]):\n",
        "                                    target_2[i]=target[2*i]\n",
        "                                target=target_2.to(device)\n",
        "                            \n",
        "                            # Forward pass\n",
        "                            output = model(data)\n",
        "                            pred_sig=torch.sigmoid(output)\n",
        "                            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "                        model_auc[idx].append(np.mean(auc))\n",
        "                        print('Grid ', grid+1, ' with training fold ', idx+1, ' & learning steps ',learning_steps_list[len(model_auc[idx])-1], ' showed AUC of ' ,np.mean(auc))\n",
        "    \n",
        "    print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "    for n in range(5):\n",
        "        AUC=(model_auc[0][n]+model_auc[1][n]+model_auc[2][n])/3\n",
        "        if AUC>best_AUC:\n",
        "            best_AUC=AUC\n",
        "            best_learning_steps=learning_steps_list[n]\n",
        "            best_LearningRate=model.learning_rate\n",
        "            best_LearningMomentum=model.momentum_rate\n",
        "            best_neuType=model.neuType\n",
        "            best_poolType=model.poolType\n",
        "            best_sigmaConv=model.sigmaConv\n",
        "            best_dropprob=model.dropprob\n",
        "            best_sigmaNeu=model.sigmaNeu\n",
        "            best_beta1=model.beta1\n",
        "            best_beta2=model.beta2\n",
        "            best_beta3=model.beta3\n",
        "            at_grid = grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best pooling layer type =  maxavg\n",
            "best neural network type =  hidden\n",
            "best AUC =  0.9503477551326501\n",
            "best learning_steps =  20000\n",
            "best learning rate =  0.00508700643696489\n",
            "best momentum =  0.9778085208494118\n",
            "best sigmaConv =  3.468664299103713e-05\n",
            "best dropprob =  1.0\n",
            "best sigmaNeu =  0.0011401518016726858\n",
            "best beta1 =  8.557828372420643e-07\n",
            "best beta2 =  9.518932406578909e-07\n",
            "best beta3 =  4.3250412414652915e-07\n",
            "At grid  0\n"
          ]
        }
      ],
      "source": [
        "# Save The Best Hyperparameters\n",
        "\n",
        "print('best pooling layer type = ', best_poolType)\n",
        "print('best neural network type = ', best_neuType)\n",
        "print('best AUC = ', best_AUC)\n",
        "print('best learning_steps = ', best_learning_steps)\n",
        "print('best learning rate = ', best_LearningRate)\n",
        "print('best momentum = ', best_LearningMomentum)\n",
        "print('best sigmaConv = ', best_sigmaConv)\n",
        "print('best dropprob = ', best_dropprob)\n",
        "print('best sigmaNeu = ', best_sigmaNeu)\n",
        "print('best beta1 = ', best_beta1)\n",
        "print('best beta2 = ', best_beta2)\n",
        "print('best beta3 = ', best_beta3)\n",
        "print('At grid ', at_grid)\n",
        "\n",
        "hyperparameters = {'pool_type': best_poolType,\n",
        "                   'neu_type':best_neuType,\n",
        "                   'learning_steps':best_learning_steps,\n",
        "                   'learning_rate':best_LearningRate, \n",
        "                   'momentum':best_LearningMomentum,\n",
        "                   'sigmaConv':best_sigmaConv,\n",
        "                   'dropprob':best_dropprob,\n",
        "                   'sigmaNeu':best_sigmaNeu,\n",
        "                   'beta1':best_beta1, \n",
        "                   'beta2':best_beta2,\n",
        "                   'beta3':best_beta3}\n",
        "\n",
        "torch.save(hyperparameters, './Hyperparameters/' + name + '.pth') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "fkrEJTXuz8GW",
        "outputId": "cdc778fd-1557-47cd-bccb-7ffcc5ea8fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for model  1  =  0.9675950990537284  while best =  0\n",
            "AUC for model  2  =  0.9629904855623961  while best =  0.9675950990537284\n",
            "AUC for model  3  =  0.9691006904696536  while best =  0.9675950990537284\n",
            "AUC for model  4  =  0.9564252822198489  while best =  0.9691006904696536\n",
            "AUC for model  5  =  0.9672933481971123  while best =  0.9691006904696536\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "best_AUC=0\n",
        "\n",
        "best_hyperparameters = torch.load('./Hyperparameters/' + name + '.pth')\n",
        "best_poolType=best_hyperparameters['pool_type']\n",
        "best_neuType=best_hyperparameters['neu_type']\n",
        "best_learning_steps=best_hyperparameters['learning_steps']\n",
        "best_LearningRate=best_hyperparameters['learning_rate']\n",
        "best_dropprob=best_hyperparameters['dropprob']\n",
        "best_LearningMomentum=best_hyperparameters['momentum']\n",
        "best_sigmaConv=best_hyperparameters['sigmaConv']\n",
        "best_sigmaNeu=best_hyperparameters['sigmaNeu']\n",
        "best_beta1=best_hyperparameters['beta1']\n",
        "best_beta2=best_hyperparameters['beta2']\n",
        "best_beta3=best_hyperparameters['beta3']\n",
        "\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for model_number in range(num_training_model):\n",
        "\n",
        "    model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'training',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=False).to(device)\n",
        "\n",
        "    if model.neuType=='nohidden':\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "    train_loader=all_dataloader\n",
        "    valid_loader=all_dataloader\n",
        "    learning_steps=0\n",
        "\n",
        "    while learning_steps<=best_learning_steps:\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            \n",
        "            if model.neuType=='nohidden':\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "            else:\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            learning_steps+=1\n",
        "            \n",
        "    with torch.no_grad():\n",
        "        model.mode='test'\n",
        "        auc=[]\n",
        "        for i, (data, target) in enumerate(valid_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2), 1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            pred_sig=torch.sigmoid(output)\n",
        "            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "        AUC_training=np.mean(auc)\n",
        "        print('AUC for model ', model_number+1,' = ', AUC_training, ' while best = ', best_AUC)\n",
        "        if AUC_training > best_AUC:\n",
        "            state = {'conv': model.wConv,\n",
        "                     'rect':model.wRect,\n",
        "                     'wHidden':model.wHidden,\n",
        "                     'wHiddenBias':model.wHiddenBias,\n",
        "                     'wNeu':model.wNeu,\n",
        "                     'wNeuBias':model.wNeuBias}\n",
        "            torch.save(state, './Models/' + name + '.pth')\n",
        "            best_AUC = AUC_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "JetF0ajS4faT",
        "outputId": "a05ac166-fbef-4725-8a8d-221ab8c7e088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9691006904696536\n"
          ]
        }
      ],
      "source": [
        "# Training Performance\n",
        "\n",
        "checkpoint = torch.load('./Models/'+ name + '.pth')\n",
        "model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'test',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=reverse_mode).to(device)\n",
        "model.wConv=checkpoint['conv']\n",
        "model.wRect=checkpoint['rect']\n",
        "model.wHidden=checkpoint['wHidden']\n",
        "model.wHiddenBias=checkpoint['wHiddenBias']\n",
        "model.wNeu=checkpoint['wNeu']\n",
        "model.wNeuBias=checkpoint['wNeuBias']\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(valid_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        if model.reverse_complemet_mode:\n",
        "          target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "          for i in range(target_2.shape[0]):\n",
        "            target_2[i]=target[2*i]\n",
        "          target=target_2.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred_sig=torch.sigmoid(output)\n",
        "        pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "              \n",
        "      AUC_training=np.mean(auc)\n",
        "      print(AUC_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "C4oqk1HnfQQw",
        "outputId": "d57c9cc3-de9f-4c97-f07d-31c2e5d9ea50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC on test data =  0.9507240000000001\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "\n",
        "test_loader = test_dataset_loader(test_dataset_path, motif_len)\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "          \n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #                         \n",
        "      AUC_test=np.mean(auc)\n",
        "      print('AUC on test data = ', AUC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AtHbPeAohR6m"
      },
      "outputs": [],
      "source": [
        "# write results\n",
        "\n",
        "with open(\"./results/AUC_training.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Train : \")\n",
        "    file.write(str(round(AUC_training, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()\n",
        "\n",
        "with open(\"./results/AUC_testing.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Test : \")\n",
        "    file.write(str(round(AUC_test, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepBind_colab_finale.ipynb",
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
