{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "colab_type": "code",
        "id": "T_Goiz940CV9",
        "outputId": "41f5e88b-c037-41c2-fd7b-5114331fed08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.2\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import metrics\n",
        "from utils import logsampler, sqrtsampler, datasets, dataset_loader, test_dataset_loader\n",
        "from network import ConvNet, ConvNet_test\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9mOZziHBz8FT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./data/encode/CTCFL_K562_CTCFL_(SC-98982)_HudsonAlpha_AC.seq.gz\n",
            "./data/encode/CTCFL_K562_CTCFL_(SC-98982)_HudsonAlpha_B.seq.gz\n",
            "CTCFL_K562_CTCFL_(SC-98982)_HudsonAlpha\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "num_motif = 16 # number of motif detector (filter in CNN)\n",
        "motif_len = 24\n",
        "batch_size = 64\n",
        "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
        "reverse_mode=False\n",
        "num_grid_search = 5 # too small\n",
        "num_training_model = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Settings\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# dataset path\n",
        "\n",
        "path = './data/encode/'\n",
        "all_dataset_names = datasets(path)\n",
        "data_idx = 1 # ELK1_GM12878_ELK1_(1277-1)_Stanford\n",
        "dataset_name = all_dataset_names[data_idx]\n",
        "\n",
        "train_dataset_path = dataset_name[0]\n",
        "test_dataset_path = dataset_name[1]\n",
        "print(train_dataset_path)\n",
        "print(test_dataset_path)\n",
        "\n",
        "name = train_dataset_path.split(path)[1].split(\"_AC\")[0]\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GwYhmKt6z8Fn"
      },
      "outputs": [],
      "source": [
        "train_dataloader, valid_dataloader, all_dataloader = dataset_loader(train_dataset_path, batch_size, reverse_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "colab_type": "code",
        "id": "3_ACNZE2z8GE",
        "outputId": "592d2faf-ecc8-4646-fdf7-a86fc6ee4611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid  1  with training fold  1  & learning steps  4000  showed AUC of  0.5093103741098202\n",
            "Grid  1  with training fold  1  & learning steps  8000  showed AUC of  0.757472630872064\n",
            "Grid  1  with training fold  1  & learning steps  12000  showed AUC of  0.8398357657108945\n",
            "Grid  1  with training fold  1  & learning steps  16000  showed AUC of  0.8369950571589205\n",
            "Grid  1  with training fold  1  & learning steps  20000  showed AUC of  0.840277946964018\n",
            "Grid  1  with training fold  2  & learning steps  4000  showed AUC of  0.5233094975949525\n",
            "Grid  1  with training fold  2  & learning steps  8000  showed AUC of  0.6135897968984259\n",
            "Grid  1  with training fold  2  & learning steps  12000  showed AUC of  0.9366187804535232\n",
            "Grid  1  with training fold  2  & learning steps  16000  showed AUC of  0.943850984663918\n",
            "Grid  1  with training fold  2  & learning steps  20000  showed AUC of  0.9436486834707647\n",
            "Grid  1  with training fold  3  & learning steps  4000  showed AUC of  0.4927661156400966\n",
            "Grid  1  with training fold  3  & learning steps  8000  showed AUC of  0.8856671195652174\n",
            "Grid  1  with training fold  3  & learning steps  12000  showed AUC of  0.9357340353260869\n",
            "Grid  1  with training fold  3  & learning steps  16000  showed AUC of  0.9440636699879228\n",
            "Grid  1  with training fold  3  & learning steps  20000  showed AUC of  0.9432487545289855\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  2  with training fold  1  & learning steps  4000  showed AUC of  0.9624575407608695\n",
            "Grid  2  with training fold  1  & learning steps  8000  showed AUC of  0.9616627623688155\n",
            "Grid  2  with training fold  1  & learning steps  12000  showed AUC of  0.9620129583645677\n",
            "Grid  2  with training fold  1  & learning steps  16000  showed AUC of  0.9626493198713143\n",
            "Grid  2  with training fold  1  & learning steps  20000  showed AUC of  0.9605942926974013\n",
            "Grid  2  with training fold  2  & learning steps  4000  showed AUC of  0.9571913066904048\n",
            "Grid  2  with training fold  2  & learning steps  8000  showed AUC of  0.9569140820214893\n",
            "Grid  2  with training fold  2  & learning steps  12000  showed AUC of  0.9574281023550725\n",
            "Grid  2  with training fold  2  & learning steps  16000  showed AUC of  0.9583186922163918\n",
            "Grid  2  with training fold  2  & learning steps  20000  showed AUC of  0.9568898460925787\n",
            "Grid  2  with training fold  3  & learning steps  4000  showed AUC of  0.9441176026570048\n",
            "Grid  2  with training fold  3  & learning steps  8000  showed AUC of  0.9423325407608696\n",
            "Grid  2  with training fold  3  & learning steps  12000  showed AUC of  0.9448847750603865\n",
            "Grid  2  with training fold  3  & learning steps  16000  showed AUC of  0.9417700407608696\n",
            "Grid  2  with training fold  3  & learning steps  20000  showed AUC of  0.9409471995772947\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  3  with training fold  1  & learning steps  4000  showed AUC of  0.9678503131246877\n",
            "Grid  3  with training fold  1  & learning steps  8000  showed AUC of  0.96892329226012\n",
            "Grid  3  with training fold  1  & learning steps  12000  showed AUC of  0.9675975879247877\n",
            "Grid  3  with training fold  1  & learning steps  16000  showed AUC of  0.9661879411856572\n",
            "Grid  3  with training fold  1  & learning steps  20000  showed AUC of  0.9668308423913043\n",
            "Grid  3  with training fold  2  & learning steps  4000  showed AUC of  0.9514563030984509\n",
            "Grid  3  with training fold  2  & learning steps  8000  showed AUC of  0.951073642866067\n",
            "Grid  3  with training fold  2  & learning steps  12000  showed AUC of  0.949014106228136\n",
            "Grid  3  with training fold  2  & learning steps  16000  showed AUC of  0.9504362271989005\n",
            "Grid  3  with training fold  2  & learning steps  20000  showed AUC of  0.9492693887431285\n",
            "Grid  3  with training fold  3  & learning steps  4000  showed AUC of  0.9476334541062802\n",
            "Grid  3  with training fold  3  & learning steps  8000  showed AUC of  0.9479479544082126\n",
            "Grid  3  with training fold  3  & learning steps  12000  showed AUC of  0.9442982336956521\n",
            "Grid  3  with training fold  3  & learning steps  16000  showed AUC of  0.9450545742753623\n",
            "Grid  3  with training fold  3  & learning steps  20000  showed AUC of  0.9455822388285025\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  4  with training fold  1  & learning steps  4000  showed AUC of  0.9607581170352324\n",
            "Grid  4  with training fold  1  & learning steps  8000  showed AUC of  0.9631777665854573\n",
            "Grid  4  with training fold  1  & learning steps  12000  showed AUC of  0.9632651642928536\n",
            "Grid  4  with training fold  1  & learning steps  16000  showed AUC of  0.9604379060469765\n",
            "Grid  4  with training fold  1  & learning steps  20000  showed AUC of  0.9604998282108946\n",
            "Grid  4  with training fold  2  & learning steps  4000  showed AUC of  0.9615661114755122\n",
            "Grid  4  with training fold  2  & learning steps  8000  showed AUC of  0.9633459442153922\n",
            "Grid  4  with training fold  2  & learning steps  12000  showed AUC of  0.9619033061594203\n",
            "Grid  4  with training fold  2  & learning steps  16000  showed AUC of  0.9606624422163919\n",
            "Grid  4  with training fold  2  & learning steps  20000  showed AUC of  0.9610535942966018\n",
            "Grid  4  with training fold  3  & learning steps  4000  showed AUC of  0.9492715504227054\n",
            "Grid  4  with training fold  3  & learning steps  8000  showed AUC of  0.950843410326087\n",
            "Grid  4  with training fold  3  & learning steps  12000  showed AUC of  0.9517880434782608\n",
            "Grid  4  with training fold  3  & learning steps  16000  showed AUC of  0.9465693689613527\n",
            "Grid  4  with training fold  3  & learning steps  20000  showed AUC of  0.9446716108091787\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  5  with training fold  1  & learning steps  4000  showed AUC of  0.7805337175162419\n",
            "Grid  5  with training fold  1  & learning steps  8000  showed AUC of  0.6938171344015492\n",
            "Grid  5  with training fold  1  & learning steps  12000  showed AUC of  0.6942262852948525\n",
            "Grid  5  with training fold  1  & learning steps  16000  showed AUC of  0.6882992780953273\n",
            "Grid  5  with training fold  1  & learning steps  20000  showed AUC of  0.6929644162293853\n",
            "Grid  5  with training fold  2  & learning steps  4000  showed AUC of  0.9432006457708646\n",
            "Grid  5  with training fold  2  & learning steps  8000  showed AUC of  0.9495766765054973\n",
            "Grid  5  with training fold  2  & learning steps  12000  showed AUC of  0.9469159853666917\n",
            "Grid  5  with training fold  2  & learning steps  16000  showed AUC of  0.948610030922039\n",
            "Grid  5  with training fold  2  & learning steps  20000  showed AUC of  0.9495968519646426\n",
            "Grid  5  with training fold  3  & learning steps  4000  showed AUC of  0.9070875037741546\n",
            "Grid  5  with training fold  3  & learning steps  8000  showed AUC of  0.901571746678744\n",
            "Grid  5  with training fold  3  & learning steps  12000  showed AUC of  0.9060930706521739\n",
            "Grid  5  with training fold  3  & learning steps  16000  showed AUC of  0.9042925158514492\n",
            "Grid  5  with training fold  3  & learning steps  20000  showed AUC of  0.90302913647343\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Grid Search\n",
        "\n",
        "best_AUC=0\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for grid in range(num_grid_search):\n",
        "    \n",
        "    # randomly select hyperparameters\n",
        "    pool_List=['max','maxavg']        \n",
        "    random_pool=random.choice(pool_List)\n",
        "    neuType_list=['hidden','nohidden']\n",
        "    random_neuType=random.choice(neuType_list)\n",
        "    dropoutList=[0.5,0.75,1.0] \n",
        "    dropprob=random.choice(dropoutList)\n",
        "    learning_rate=logsampler(0.0005,0.05)\n",
        "    momentum_rate=sqrtsampler(0.95,0.99)  \n",
        "    sigmaConv=logsampler(10**-7,10**-3)   \n",
        "    sigmaNeu=logsampler(10**-5,10**-2) \n",
        "    beta1=logsampler(10**-15,10**-3)\n",
        "    beta2=logsampler(10**-10,10**-3)\n",
        "    beta3=logsampler(10**-10,10**-3)\n",
        "\n",
        "    model_auc=[[],[],[]]\n",
        "\n",
        "    for idx in range(3):\n",
        "        model = ConvNet(num_motif,motif_len,random_pool,random_neuType,'training',dropprob,learning_rate,momentum_rate,sigmaConv,sigmaNeu,beta1,beta2,beta3, device, reverse_complemet_mode=reverse_mode).to(device)\n",
        "        if random_neuType=='nohidden':\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        train_loader=train_dataloader[idx]\n",
        "        valid_loader=valid_dataloader[idx]\n",
        "\n",
        "        learning_steps=0\n",
        "\n",
        "        while learning_steps<=20000:\n",
        "            model.mode='training'\n",
        "            auc=[]\n",
        "            for i, (data, target) in enumerate(train_loader):\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "                if model.reverse_complemet_mode:\n",
        "                    target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                    for i in range(target_2.shape[0]):\n",
        "                        target_2[i]=target[2*i]\n",
        "                    target=target_2.to(device)\n",
        "                \n",
        "                # Forward pass\n",
        "                output = model(data)\n",
        "                \n",
        "                if model.neuType=='nohidden':\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "                else:\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                learning_steps+=1\n",
        "    \n",
        "                if learning_steps% 4000==0:\n",
        "                    with torch.no_grad():\n",
        "                        model.mode='test'\n",
        "                        auc=[]\n",
        "                        for i, (data, target) in enumerate(valid_loader):\n",
        "                            data = data.to(device)\n",
        "                            target = target.to(device)\n",
        "                            if model.reverse_complemet_mode:\n",
        "                                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                                for i in range(target_2.shape[0]):\n",
        "                                    target_2[i]=target[2*i]\n",
        "                                target=target_2.to(device)\n",
        "                            \n",
        "                            # Forward pass\n",
        "                            output = model(data)\n",
        "                            pred_sig=torch.sigmoid(output)\n",
        "                            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "                        model_auc[idx].append(np.mean(auc))\n",
        "                        print('Grid ', grid+1, ' with training fold ', idx+1, ' & learning steps ',learning_steps_list[len(model_auc[idx])-1], ' showed AUC of ' ,np.mean(auc))\n",
        "    \n",
        "    print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "    for n in range(5):\n",
        "        AUC=(model_auc[0][n]+model_auc[1][n]+model_auc[2][n])/3\n",
        "        if AUC>best_AUC:\n",
        "            best_AUC=AUC\n",
        "            best_learning_steps=learning_steps_list[n]\n",
        "            best_LearningRate=model.learning_rate\n",
        "            best_LearningMomentum=model.momentum_rate\n",
        "            best_neuType=model.neuType\n",
        "            best_poolType=model.poolType\n",
        "            best_sigmaConv=model.sigmaConv\n",
        "            best_dropprob=model.dropprob\n",
        "            best_sigmaNeu=model.sigmaNeu\n",
        "            best_beta1=model.beta1\n",
        "            best_beta2=model.beta2\n",
        "            best_beta3=model.beta3\n",
        "            at_grid = grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best pooling layer type =  maxavg\n",
            "best neural network type =  hidden\n",
            "best AUC =  0.9591223737089788\n",
            "best learning_steps =  8000\n",
            "best learning rate =  0.017930592018429472\n",
            "best momentum =  0.9739214561512546\n",
            "best sigmaConv =  2.2932367829783597e-07\n",
            "best dropprob =  1.0\n",
            "best sigmaNeu =  3.095323093962562e-05\n",
            "best beta1 =  3.58896758956335e-08\n",
            "best beta2 =  1.993989361385045e-09\n",
            "best beta3 =  1.0411736980045588e-07\n",
            "At grid  3\n"
          ]
        }
      ],
      "source": [
        "# Save The Best Hyperparameters\n",
        "\n",
        "print('best pooling layer type = ', best_poolType)\n",
        "print('best neural network type = ', best_neuType)\n",
        "print('best AUC = ', best_AUC)\n",
        "print('best learning_steps = ', best_learning_steps)\n",
        "print('best learning rate = ', best_LearningRate)\n",
        "print('best momentum = ', best_LearningMomentum)\n",
        "print('best sigmaConv = ', best_sigmaConv)\n",
        "print('best dropprob = ', best_dropprob)\n",
        "print('best sigmaNeu = ', best_sigmaNeu)\n",
        "print('best beta1 = ', best_beta1)\n",
        "print('best beta2 = ', best_beta2)\n",
        "print('best beta3 = ', best_beta3)\n",
        "print('At grid ', at_grid)\n",
        "\n",
        "hyperparameters = {'pool_type': best_poolType,\n",
        "                   'neu_type':best_neuType,\n",
        "                   'learning_steps':best_learning_steps,\n",
        "                   'learning_rate':best_LearningRate, \n",
        "                   'momentum':best_LearningMomentum,\n",
        "                   'sigmaConv':best_sigmaConv,\n",
        "                   'dropprob':best_dropprob,\n",
        "                   'sigmaNeu':best_sigmaNeu,\n",
        "                   'beta1':best_beta1, \n",
        "                   'beta2':best_beta2,\n",
        "                   'beta3':best_beta3}\n",
        "\n",
        "torch.save(hyperparameters, './Hyperparameters/' + name + '.pth') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "fkrEJTXuz8GW",
        "outputId": "cdc778fd-1557-47cd-bccb-7ffcc5ea8fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for model  1  =  0.9765495471014493  while best =  0\n",
            "AUC for model  2  =  0.9802324818840579  while best =  0.9765495471014493\n",
            "AUC for model  3  =  0.9758638179347827  while best =  0.9802324818840579\n",
            "AUC for model  4  =  0.9807605434782609  while best =  0.9802324818840579\n",
            "AUC for model  5  =  0.9713865036231885  while best =  0.9807605434782609\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "best_AUC=0\n",
        "\n",
        "best_hyperparameters = torch.load('./Hyperparameters/' + name + '.pth')\n",
        "best_poolType=best_hyperparameters['pool_type']\n",
        "best_neuType=best_hyperparameters['neu_type']\n",
        "best_learning_steps=best_hyperparameters['learning_steps']\n",
        "best_LearningRate=best_hyperparameters['learning_rate']\n",
        "best_dropprob=best_hyperparameters['dropprob']\n",
        "best_LearningMomentum=best_hyperparameters['momentum']\n",
        "best_sigmaConv=best_hyperparameters['sigmaConv']\n",
        "best_sigmaNeu=best_hyperparameters['sigmaNeu']\n",
        "best_beta1=best_hyperparameters['beta1']\n",
        "best_beta2=best_hyperparameters['beta2']\n",
        "best_beta3=best_hyperparameters['beta3']\n",
        "\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for model_number in range(num_training_model):\n",
        "\n",
        "    model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'training',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=False).to(device)\n",
        "\n",
        "    if model.neuType=='nohidden':\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "    train_loader=all_dataloader\n",
        "    valid_loader=all_dataloader\n",
        "    learning_steps=0\n",
        "\n",
        "    while learning_steps<=best_learning_steps:\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            \n",
        "            if model.neuType=='nohidden':\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "            else:\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            learning_steps+=1\n",
        "            \n",
        "    with torch.no_grad():\n",
        "        model.mode='test'\n",
        "        auc=[]\n",
        "        for i, (data, target) in enumerate(valid_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2), 1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            pred_sig=torch.sigmoid(output)\n",
        "            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "        AUC_training=np.mean(auc)\n",
        "        print('AUC for model ', model_number+1,' = ', AUC_training, ' while best = ', best_AUC)\n",
        "        if AUC_training > best_AUC:\n",
        "            state = {'conv': model.wConv,\n",
        "                     'rect':model.wRect,\n",
        "                     'wHidden':model.wHidden,\n",
        "                     'wHiddenBias':model.wHiddenBias,\n",
        "                     'wNeu':model.wNeu,\n",
        "                     'wNeuBias':model.wNeuBias}\n",
        "            torch.save(state, './Models/' + name + '.pth')\n",
        "            best_AUC = AUC_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "JetF0ajS4faT",
        "outputId": "a05ac166-fbef-4725-8a8d-221ab8c7e088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9807605434782609\n"
          ]
        }
      ],
      "source": [
        "# Training Performance\n",
        "\n",
        "checkpoint = torch.load('./Models/'+ name + '.pth')\n",
        "model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'test',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=reverse_mode).to(device)\n",
        "model.wConv=checkpoint['conv']\n",
        "model.wRect=checkpoint['rect']\n",
        "model.wHidden=checkpoint['wHidden']\n",
        "model.wHiddenBias=checkpoint['wHiddenBias']\n",
        "model.wNeu=checkpoint['wNeu']\n",
        "model.wNeuBias=checkpoint['wNeuBias']\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(valid_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        if model.reverse_complemet_mode:\n",
        "          target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "          for i in range(target_2.shape[0]):\n",
        "            target_2[i]=target[2*i]\n",
        "          target=target_2.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred_sig=torch.sigmoid(output)\n",
        "        pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "              \n",
        "      AUC_training=np.mean(auc)\n",
        "      print(AUC_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "C4oqk1HnfQQw",
        "outputId": "d57c9cc3-de9f-4c97-f07d-31c2e5d9ea50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC on test data =  0.97054\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "\n",
        "test_loader = test_dataset_loader(test_dataset_path, motif_len)\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "          \n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #                         \n",
        "      AUC_test=np.mean(auc)\n",
        "      print('AUC on test data = ', AUC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AtHbPeAohR6m"
      },
      "outputs": [],
      "source": [
        "# write results\n",
        "\n",
        "with open(\"./results/AUC_training.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Train : \")\n",
        "    file.write(str(round(AUC_training, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()\n",
        "\n",
        "with open(\"./results/AUC_testing.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Test : \")\n",
        "    file.write(str(round(AUC_test, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepBind_colab_finale.ipynb",
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
