{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "colab_type": "code",
        "id": "T_Goiz940CV9",
        "outputId": "41f5e88b-c037-41c2-fd7b-5114331fed08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.2\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import metrics\n",
        "from utils import logsampler, sqrtsampler, datasets, dataset_loader, test_dataset_loader\n",
        "from network import ConvNet, ConvNet_test\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9mOZziHBz8FT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./data/encode/ZBTB7A_HepG2_ZBTB7A_(SC-34508)_HudsonAlpha_AC.seq.gz\n",
            "./data/encode/ZBTB7A_HepG2_ZBTB7A_(SC-34508)_HudsonAlpha_B.seq.gz\n",
            "ZBTB7A_HepG2_ZBTB7A_(SC-34508)_HudsonAlpha\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "num_motif = 16 # number of motif detector (filter in CNN)\n",
        "motif_len = 24\n",
        "batch_size = 64\n",
        "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
        "reverse_mode=False\n",
        "num_grid_search = 5 # too small\n",
        "num_training_model = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Settings\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# dataset path\n",
        "\n",
        "path = './data/encode/'\n",
        "all_dataset_names = datasets(path)\n",
        "data_idx = 9 # from 0 to 9\n",
        "dataset_name = all_dataset_names[data_idx]\n",
        "\n",
        "train_dataset_path = dataset_name[0]\n",
        "test_dataset_path = dataset_name[1]\n",
        "print(train_dataset_path)\n",
        "print(test_dataset_path)\n",
        "\n",
        "name = train_dataset_path.split(path)[1].split(\"_AC\")[0]\n",
        "print(name)\n",
        "\n",
        "train_dataloader, valid_dataloader, all_dataloader = dataset_loader(train_dataset_path, batch_size, reverse_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "colab_type": "code",
        "id": "3_ACNZE2z8GE",
        "outputId": "592d2faf-ecc8-4646-fdf7-a86fc6ee4611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid  1  with training fold  1  & learning steps  4000  showed AUC of  0.831784426510989\n",
            "Grid  1  with training fold  1  & learning steps  8000  showed AUC of  0.8327931833791209\n",
            "Grid  1  with training fold  1  & learning steps  12000  showed AUC of  0.8318380837912088\n",
            "Grid  1  with training fold  1  & learning steps  16000  showed AUC of  0.8339521806318682\n",
            "Grid  1  with training fold  1  & learning steps  20000  showed AUC of  0.8369891826923077\n",
            "Grid  1  with training fold  2  & learning steps  4000  showed AUC of  0.8478386847527473\n",
            "Grid  1  with training fold  2  & learning steps  8000  showed AUC of  0.8563916552197802\n",
            "Grid  1  with training fold  2  & learning steps  12000  showed AUC of  0.8602442479395604\n",
            "Grid  1  with training fold  2  & learning steps  16000  showed AUC of  0.8636461195054945\n",
            "Grid  1  with training fold  2  & learning steps  20000  showed AUC of  0.8642363495879121\n",
            "Grid  1  with training fold  3  & learning steps  4000  showed AUC of  0.8201619625508575\n",
            "Grid  1  with training fold  3  & learning steps  8000  showed AUC of  0.8296982537358836\n",
            "Grid  1  with training fold  3  & learning steps  12000  showed AUC of  0.8336915436423438\n",
            "Grid  1  with training fold  3  & learning steps  16000  showed AUC of  0.8423193743702233\n",
            "Grid  1  with training fold  3  & learning steps  20000  showed AUC of  0.8439330660148675\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  2  with training fold  1  & learning steps  4000  showed AUC of  0.8395754635989011\n",
            "Grid  2  with training fold  1  & learning steps  8000  showed AUC of  0.8509293440934066\n",
            "Grid  2  with training fold  1  & learning steps  12000  showed AUC of  0.8483537946428571\n",
            "Grid  2  with training fold  1  & learning steps  16000  showed AUC of  0.8469479739010989\n",
            "Grid  2  with training fold  1  & learning steps  20000  showed AUC of  0.8460250686813187\n",
            "Grid  2  with training fold  2  & learning steps  4000  showed AUC of  0.8574540693681318\n",
            "Grid  2  with training fold  2  & learning steps  8000  showed AUC of  0.8602549793956044\n",
            "Grid  2  with training fold  2  & learning steps  12000  showed AUC of  0.8563862894917582\n",
            "Grid  2  with training fold  2  & learning steps  16000  showed AUC of  0.8551038804945055\n",
            "Grid  2  with training fold  2  & learning steps  20000  showed AUC of  0.8582428313873627\n",
            "Grid  2  with training fold  3  & learning steps  4000  showed AUC of  0.8513942129453591\n",
            "Grid  2  with training fold  3  & learning steps  8000  showed AUC of  0.8458169007139056\n",
            "Grid  2  with training fold  3  & learning steps  12000  showed AUC of  0.8382619556589604\n",
            "Grid  2  with training fold  3  & learning steps  16000  showed AUC of  0.8415353096838283\n",
            "Grid  2  with training fold  3  & learning steps  20000  showed AUC of  0.8391220688643104\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  3  with training fold  1  & learning steps  4000  showed AUC of  0.7832353193681318\n",
            "Grid  3  with training fold  1  & learning steps  8000  showed AUC of  0.7514487465659341\n",
            "Grid  3  with training fold  1  & learning steps  12000  showed AUC of  0.7683454241071429\n",
            "Grid  3  with training fold  1  & learning steps  16000  showed AUC of  0.7628723815247253\n",
            "Grid  3  with training fold  1  & learning steps  20000  showed AUC of  0.7500160971840659\n",
            "Grid  3  with training fold  2  & learning steps  4000  showed AUC of  0.7484546703296703\n",
            "Grid  3  with training fold  2  & learning steps  8000  showed AUC of  0.7918151184752747\n",
            "Grid  3  with training fold  2  & learning steps  12000  showed AUC of  0.7837772578983516\n",
            "Grid  3  with training fold  2  & learning steps  16000  showed AUC of  0.7775637448489011\n",
            "Grid  3  with training fold  2  & learning steps  20000  showed AUC of  0.7954584478021978\n",
            "Grid  3  with training fold  3  & learning steps  4000  showed AUC of  0.7367730533955664\n",
            "Grid  3  with training fold  3  & learning steps  8000  showed AUC of  0.7308785690817617\n",
            "Grid  3  with training fold  3  & learning steps  12000  showed AUC of  0.7185026752145994\n",
            "Grid  3  with training fold  3  & learning steps  16000  showed AUC of  0.7196110600985304\n",
            "Grid  3  with training fold  3  & learning steps  20000  showed AUC of  0.7121267978345184\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  4  with training fold  1  & learning steps  4000  showed AUC of  0.8373647836538461\n",
            "Grid  4  with training fold  1  & learning steps  8000  showed AUC of  0.8359804258241759\n",
            "Grid  4  with training fold  1  & learning steps  12000  showed AUC of  0.8363452953296703\n",
            "Grid  4  with training fold  1  & learning steps  16000  showed AUC of  0.8369140625\n",
            "Grid  4  with training fold  1  & learning steps  20000  showed AUC of  0.8354975103021978\n",
            "Grid  4  with training fold  2  & learning steps  4000  showed AUC of  0.8531292925824175\n",
            "Grid  4  with training fold  2  & learning steps  8000  showed AUC of  0.8564989697802198\n",
            "Grid  4  with training fold  2  & learning steps  12000  showed AUC of  0.8546209649725275\n",
            "Grid  4  with training fold  2  & learning steps  16000  showed AUC of  0.8548355940934066\n",
            "Grid  4  with training fold  2  & learning steps  20000  showed AUC of  0.8520024896978022\n",
            "Grid  4  with training fold  3  & learning steps  4000  showed AUC of  0.8362913409849234\n",
            "Grid  4  with training fold  3  & learning steps  8000  showed AUC of  0.8447271937621202\n",
            "Grid  4  with training fold  3  & learning steps  12000  showed AUC of  0.8429243091467357\n",
            "Grid  4  with training fold  3  & learning steps  16000  showed AUC of  0.84304632840127\n",
            "Grid  4  with training fold  3  & learning steps  20000  showed AUC of  0.8422564338235294\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  5  with training fold  1  & learning steps  4000  showed AUC of  0.8227914663461539\n",
            "Grid  5  with training fold  1  & learning steps  8000  showed AUC of  0.8385291466346154\n",
            "Grid  5  with training fold  1  & learning steps  12000  showed AUC of  0.8373003949175825\n",
            "Grid  5  with training fold  1  & learning steps  16000  showed AUC of  0.8421080872252747\n",
            "Grid  5  with training fold  1  & learning steps  20000  showed AUC of  0.8415929773351648\n",
            "Grid  5  with training fold  2  & learning steps  4000  showed AUC of  0.8098707932692307\n",
            "Grid  5  with training fold  2  & learning steps  8000  showed AUC of  0.8302390968406593\n",
            "Grid  5  with training fold  2  & learning steps  12000  showed AUC of  0.8366135817307693\n",
            "Grid  5  with training fold  2  & learning steps  16000  showed AUC of  0.8397686298076923\n",
            "Grid  5  with training fold  2  & learning steps  20000  showed AUC of  0.8414856627747253\n",
            "Grid  5  with training fold  3  & learning steps  4000  showed AUC of  0.8237931679317655\n",
            "Grid  5  with training fold  3  & learning steps  8000  showed AUC of  0.8359976184336858\n",
            "Grid  5  with training fold  3  & learning steps  12000  showed AUC of  0.84110605144207\n",
            "Grid  5  with training fold  3  & learning steps  16000  showed AUC of  0.8435537517467394\n",
            "Grid  5  with training fold  3  & learning steps  20000  showed AUC of  0.8433146148023689\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Grid Search\n",
        "\n",
        "best_AUC=0\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for grid in range(num_grid_search):\n",
        "    \n",
        "    # randomly select hyperparameters\n",
        "    pool_List=['max','maxavg']        \n",
        "    random_pool=random.choice(pool_List)\n",
        "    neuType_list=['hidden','nohidden']\n",
        "    random_neuType=random.choice(neuType_list)\n",
        "    dropoutList=[0.5,0.75,1.0] \n",
        "    dropprob=random.choice(dropoutList)\n",
        "    learning_rate=logsampler(0.0005,0.05)\n",
        "    momentum_rate=sqrtsampler(0.95,0.99)  \n",
        "    sigmaConv=logsampler(10**-7,10**-3)   \n",
        "    sigmaNeu=logsampler(10**-5,10**-2) \n",
        "    beta1=logsampler(10**-15,10**-3)\n",
        "    beta2=logsampler(10**-10,10**-3)\n",
        "    beta3=logsampler(10**-10,10**-3)\n",
        "\n",
        "    model_auc=[[],[],[]]\n",
        "\n",
        "    for idx in range(3):\n",
        "        model = ConvNet(num_motif,motif_len,random_pool,random_neuType,'training',dropprob,learning_rate,momentum_rate,sigmaConv,sigmaNeu,beta1,beta2,beta3, device, reverse_complemet_mode=reverse_mode).to(device)\n",
        "        if random_neuType=='nohidden':\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        train_loader=train_dataloader[idx]\n",
        "        valid_loader=valid_dataloader[idx]\n",
        "\n",
        "        learning_steps=0\n",
        "\n",
        "        while learning_steps<=20000:\n",
        "            model.mode='training'\n",
        "            auc=[]\n",
        "            for i, (data, target) in enumerate(train_loader):\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "                if model.reverse_complemet_mode:\n",
        "                    target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                    for i in range(target_2.shape[0]):\n",
        "                        target_2[i]=target[2*i]\n",
        "                    target=target_2.to(device)\n",
        "                \n",
        "                # Forward pass\n",
        "                output = model(data)\n",
        "                \n",
        "                if model.neuType=='nohidden':\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "                else:\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                learning_steps+=1\n",
        "    \n",
        "                if learning_steps% 4000==0:\n",
        "                    with torch.no_grad():\n",
        "                        model.mode='test'\n",
        "                        auc=[]\n",
        "                        for i, (data, target) in enumerate(valid_loader):\n",
        "                            data = data.to(device)\n",
        "                            target = target.to(device)\n",
        "                            if model.reverse_complemet_mode:\n",
        "                                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                                for i in range(target_2.shape[0]):\n",
        "                                    target_2[i]=target[2*i]\n",
        "                                target=target_2.to(device)\n",
        "                            \n",
        "                            # Forward pass\n",
        "                            output = model(data)\n",
        "                            pred_sig=torch.sigmoid(output)\n",
        "                            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "                        model_auc[idx].append(np.mean(auc))\n",
        "                        print('Grid ', grid+1, ' with training fold ', idx+1, ' & learning steps ',learning_steps_list[len(model_auc[idx])-1], ' showed AUC of ' ,np.mean(auc))\n",
        "    \n",
        "    print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "    for n in range(5):\n",
        "        AUC=(model_auc[0][n]+model_auc[1][n]+model_auc[2][n])/3\n",
        "        if AUC>best_AUC:\n",
        "            best_AUC=AUC\n",
        "            best_learning_steps=learning_steps_list[n]\n",
        "            best_LearningRate=model.learning_rate\n",
        "            best_LearningMomentum=model.momentum_rate\n",
        "            best_neuType=model.neuType\n",
        "            best_poolType=model.poolType\n",
        "            best_sigmaConv=model.sigmaConv\n",
        "            best_dropprob=model.dropprob\n",
        "            best_sigmaNeu=model.sigmaNeu\n",
        "            best_beta1=model.beta1\n",
        "            best_beta2=model.beta2\n",
        "            best_beta3=model.beta3\n",
        "            at_grid = grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best pooling layer type =  max\n",
            "best neural network type =  hidden\n",
            "best AUC =  0.8523337414009721\n",
            "best learning_steps =  8000\n",
            "best learning rate =  0.021001547217364937\n",
            "best momentum =  0.9739656053712691\n",
            "best sigmaConv =  3.487458799171423e-06\n",
            "best dropprob =  0.5\n",
            "best sigmaNeu =  2.7349888416807764e-05\n",
            "best beta1 =  1.3395495434494614e-12\n",
            "best beta2 =  1.6696666266621692e-08\n",
            "best beta3 =  1.601913225115853e-07\n",
            "At grid  1\n"
          ]
        }
      ],
      "source": [
        "# Save The Best Hyperparameters\n",
        "\n",
        "print('best pooling layer type = ', best_poolType)\n",
        "print('best neural network type = ', best_neuType)\n",
        "print('best AUC = ', best_AUC)\n",
        "print('best learning_steps = ', best_learning_steps)\n",
        "print('best learning rate = ', best_LearningRate)\n",
        "print('best momentum = ', best_LearningMomentum)\n",
        "print('best sigmaConv = ', best_sigmaConv)\n",
        "print('best dropprob = ', best_dropprob)\n",
        "print('best sigmaNeu = ', best_sigmaNeu)\n",
        "print('best beta1 = ', best_beta1)\n",
        "print('best beta2 = ', best_beta2)\n",
        "print('best beta3 = ', best_beta3)\n",
        "print('At grid ', at_grid)\n",
        "\n",
        "hyperparameters = {'pool_type': best_poolType,\n",
        "                   'neu_type':best_neuType,\n",
        "                   'learning_steps':best_learning_steps,\n",
        "                   'learning_rate':best_LearningRate, \n",
        "                   'momentum':best_LearningMomentum,\n",
        "                   'sigmaConv':best_sigmaConv,\n",
        "                   'dropprob':best_dropprob,\n",
        "                   'sigmaNeu':best_sigmaNeu,\n",
        "                   'beta1':best_beta1, \n",
        "                   'beta2':best_beta2,\n",
        "                   'beta3':best_beta3}\n",
        "\n",
        "torch.save(hyperparameters, './Hyperparameters/' + name + '.pth') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "fkrEJTXuz8GW",
        "outputId": "cdc778fd-1557-47cd-bccb-7ffcc5ea8fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for model  1  =  0.9137697722599799  while best =  0\n",
            "AUC for model  2  =  0.9091229880387492  while best =  0.9137697722599799\n",
            "AUC for model  3  =  0.8898863665275798  while best =  0.9137697722599799\n",
            "AUC for model  4  =  0.9182928463069916  while best =  0.9137697722599799\n",
            "AUC for model  5  =  0.9117824337813899  while best =  0.9182928463069916\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "best_AUC=0\n",
        "\n",
        "best_hyperparameters = torch.load('./Hyperparameters/' + name + '.pth')\n",
        "best_poolType=best_hyperparameters['pool_type']\n",
        "best_neuType=best_hyperparameters['neu_type']\n",
        "best_learning_steps=best_hyperparameters['learning_steps']\n",
        "best_LearningRate=best_hyperparameters['learning_rate']\n",
        "best_dropprob=best_hyperparameters['dropprob']\n",
        "best_LearningMomentum=best_hyperparameters['momentum']\n",
        "best_sigmaConv=best_hyperparameters['sigmaConv']\n",
        "best_sigmaNeu=best_hyperparameters['sigmaNeu']\n",
        "best_beta1=best_hyperparameters['beta1']\n",
        "best_beta2=best_hyperparameters['beta2']\n",
        "best_beta3=best_hyperparameters['beta3']\n",
        "\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for model_number in range(num_training_model):\n",
        "\n",
        "    model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'training',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=False).to(device)\n",
        "\n",
        "    if model.neuType=='nohidden':\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "    train_loader=all_dataloader\n",
        "    valid_loader=all_dataloader\n",
        "    learning_steps=0\n",
        "\n",
        "    while learning_steps<=best_learning_steps:\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            \n",
        "            if model.neuType=='nohidden':\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "            else:\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            learning_steps+=1\n",
        "            \n",
        "    with torch.no_grad():\n",
        "        model.mode='test'\n",
        "        auc=[]\n",
        "        for i, (data, target) in enumerate(valid_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2), 1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            pred_sig=torch.sigmoid(output)\n",
        "            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "        AUC_training=np.mean(auc)\n",
        "        print('AUC for model ', model_number+1,' = ', AUC_training, ' while best = ', best_AUC)\n",
        "        if AUC_training > best_AUC:\n",
        "            state = {'conv': model.wConv,\n",
        "                     'rect':model.wRect,\n",
        "                     'wHidden':model.wHidden,\n",
        "                     'wHiddenBias':model.wHiddenBias,\n",
        "                     'wNeu':model.wNeu,\n",
        "                     'wNeuBias':model.wNeuBias}\n",
        "            torch.save(state, './Models/' + name + '.pth')\n",
        "            best_AUC = AUC_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "JetF0ajS4faT",
        "outputId": "a05ac166-fbef-4725-8a8d-221ab8c7e088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9182928463069916\n"
          ]
        }
      ],
      "source": [
        "# Training Performance\n",
        "\n",
        "checkpoint = torch.load('./Models/'+ name + '.pth')\n",
        "model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'test',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=reverse_mode).to(device)\n",
        "model.wConv=checkpoint['conv']\n",
        "model.wRect=checkpoint['rect']\n",
        "model.wHidden=checkpoint['wHidden']\n",
        "model.wHiddenBias=checkpoint['wHiddenBias']\n",
        "model.wNeu=checkpoint['wNeu']\n",
        "model.wNeuBias=checkpoint['wNeuBias']\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(valid_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        if model.reverse_complemet_mode:\n",
        "          target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "          for i in range(target_2.shape[0]):\n",
        "            target_2[i]=target[2*i]\n",
        "          target=target_2.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred_sig=torch.sigmoid(output)\n",
        "        pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "              \n",
        "      AUC_training=np.mean(auc)\n",
        "      print(AUC_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "C4oqk1HnfQQw",
        "outputId": "d57c9cc3-de9f-4c97-f07d-31c2e5d9ea50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC on test data =  0.7356119999999999\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "\n",
        "test_loader = test_dataset_loader(test_dataset_path, motif_len)\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "          \n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "               \n",
        "      AUC_test=np.mean(auc)\n",
        "      print('AUC on test data = ', AUC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AtHbPeAohR6m"
      },
      "outputs": [],
      "source": [
        "# write results\n",
        "\n",
        "with open(\"./results/AUC_training.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Train : \")\n",
        "    file.write(str(round(AUC_training, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()\n",
        "\n",
        "with open(\"./results/AUC_testing.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Test : \")\n",
        "    file.write(str(round(AUC_test, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepBind_colab_finale.ipynb",
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
