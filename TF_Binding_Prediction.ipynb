{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "colab_type": "code",
        "id": "T_Goiz940CV9",
        "outputId": "41f5e88b-c037-41c2-fd7b-5114331fed08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.2\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import metrics\n",
        "from utils import logsampler, sqrtsampler, datasets, dataset_loader, test_dataset_loader\n",
        "from network import ConvNet, ConvNet_test\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9mOZziHBz8FT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./data/encode/ARID3A_K562_ARID3A_(sc-8821)_Stanford_AC.seq.gz\n",
            "./data/encode/ARID3A_K562_ARID3A_(sc-8821)_Stanford_B.seq.gz\n",
            "ARID3A_K562_ARID3A_(sc-8821)_Stanford\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "num_motif = 16 # number of motif detector (filter in CNN)\n",
        "motif_len = 24\n",
        "batch_size=64\n",
        "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
        "reverse_mode=False\n",
        "num_grid_search = 5 # too small\n",
        "num_training_model = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Settings\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# dataset path\n",
        "\n",
        "path = './data/encode/'\n",
        "all_dataset_names = datasets(path)\n",
        "data_idx = 0 # ELK1_GM12878_ELK1_(1277-1)_Stanford\n",
        "dataset_name = all_dataset_names[data_idx]\n",
        "\n",
        "train_dataset_path = dataset_name[0]\n",
        "test_dataset_path = dataset_name[1]\n",
        "print(train_dataset_path)\n",
        "print(test_dataset_path)\n",
        "\n",
        "name = train_dataset_path.split(path)[1].split(\"_AC\")[0]\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GwYhmKt6z8Fn"
      },
      "outputs": [],
      "source": [
        "train_dataloader, valid_dataloader, all_dataloader = dataset_loader(train_dataset_path, batch_size, reverse_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "colab_type": "code",
        "id": "3_ACNZE2z8GE",
        "outputId": "592d2faf-ecc8-4646-fdf7-a86fc6ee4611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid  1  with training fold  1  & learning steps  4000  showed AUC of  0.7893770698632072\n",
            "Grid  1  with training fold  1  & learning steps  8000  showed AUC of  0.7945243288137425\n",
            "Grid  1  with training fold  1  & learning steps  12000  showed AUC of  0.7946531109238915\n",
            "Grid  1  with training fold  1  & learning steps  16000  showed AUC of  0.7909296945120836\n",
            "Grid  1  with training fold  1  & learning steps  20000  showed AUC of  0.7940178356242936\n",
            "Grid  1  with training fold  2  & learning steps  4000  showed AUC of  0.7823508646678247\n",
            "Grid  1  with training fold  2  & learning steps  8000  showed AUC of  0.7699463263953528\n",
            "Grid  1  with training fold  2  & learning steps  12000  showed AUC of  0.7841884526045475\n",
            "Grid  1  with training fold  2  & learning steps  16000  showed AUC of  0.7855337338358486\n",
            "Grid  1  with training fold  2  & learning steps  20000  showed AUC of  0.7831173243654843\n",
            "Grid  1  with training fold  3  & learning steps  4000  showed AUC of  0.7976603858308124\n",
            "Grid  1  with training fold  3  & learning steps  8000  showed AUC of  0.7979744687437671\n",
            "Grid  1  with training fold  3  & learning steps  12000  showed AUC of  0.7919939729842597\n",
            "Grid  1  with training fold  3  & learning steps  16000  showed AUC of  0.7999297687882289\n",
            "Grid  1  with training fold  3  & learning steps  20000  showed AUC of  0.7775452824778937\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid  2  with training fold  1  & learning steps  4000  showed AUC of  0.8431349493675621\n",
            "Grid  2  with training fold  1  & learning steps  8000  showed AUC of  0.845928290796822\n",
            "Grid  2  with training fold  1  & learning steps  12000  showed AUC of  0.8461650135463067\n",
            "Grid  2  with training fold  1  & learning steps  16000  showed AUC of  0.8451831270568779\n",
            "Grid  2  with training fold  1  & learning steps  20000  showed AUC of  0.8463794664375706\n",
            "Grid  2  with training fold  2  & learning steps  4000  showed AUC of  0.8500730165672162\n",
            "Grid  2  with training fold  2  & learning steps  8000  showed AUC of  0.8484876363980122\n",
            "Grid  2  with training fold  2  & learning steps  12000  showed AUC of  0.8468168776178445\n",
            "Grid  2  with training fold  2  & learning steps  16000  showed AUC of  0.8464820506241274\n",
            "Grid  2  with training fold  2  & learning steps  20000  showed AUC of  0.8426622829889968\n",
            "Grid  2  with training fold  3  & learning steps  4000  showed AUC of  0.8458144742911042\n",
            "Grid  2  with training fold  3  & learning steps  8000  showed AUC of  0.8484435511684729\n",
            "Grid  2  with training fold  3  & learning steps  12000  showed AUC of  0.8481456674672562\n",
            "Grid  2  with training fold  3  & learning steps  16000  showed AUC of  0.8485247095439132\n"
          ]
        }
      ],
      "source": [
        "# Grid Search\n",
        "\n",
        "best_AUC=0\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for grid in range(num_grid_search):\n",
        "    \n",
        "    # randomly select hyperparameters\n",
        "    pool_List=['max','maxavg']        \n",
        "    random_pool=random.choice(pool_List)\n",
        "    neuType_list=['hidden','nohidden']\n",
        "    random_neuType=random.choice(neuType_list)\n",
        "    dropoutList=[0.5,0.75,1.0] \n",
        "    dropprob=random.choice(dropoutList)\n",
        "    learning_rate=logsampler(0.0005,0.05)\n",
        "    momentum_rate=sqrtsampler(0.95,0.99)  \n",
        "    sigmaConv=logsampler(10**-7,10**-3)   \n",
        "    sigmaNeu=logsampler(10**-5,10**-2) \n",
        "    beta1=logsampler(10**-15,10**-3)\n",
        "    beta2=logsampler(10**-10,10**-3)\n",
        "    beta3=logsampler(10**-10,10**-3)\n",
        "\n",
        "    model_auc=[[],[],[]]\n",
        "\n",
        "    for idx in range(3):\n",
        "        model = ConvNet(num_motif,motif_len,random_pool,random_neuType,'training',dropprob,learning_rate,momentum_rate,sigmaConv,sigmaNeu,beta1,beta2,beta3, device, reverse_complemet_mode=reverse_mode).to(device)\n",
        "        if random_neuType=='nohidden':\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        train_loader=train_dataloader[idx]\n",
        "        valid_loader=valid_dataloader[idx]\n",
        "\n",
        "        learning_steps=0\n",
        "\n",
        "        while learning_steps<=20000:\n",
        "            model.mode='training'\n",
        "            auc=[]\n",
        "            for i, (data, target) in enumerate(train_loader):\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "                if model.reverse_complemet_mode:\n",
        "                    target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                    for i in range(target_2.shape[0]):\n",
        "                        target_2[i]=target[2*i]\n",
        "                    target=target_2.to(device)\n",
        "                \n",
        "                # Forward pass\n",
        "                output = model(data)\n",
        "                \n",
        "                if model.neuType=='nohidden':\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "                else:\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                learning_steps+=1\n",
        "    \n",
        "                if learning_steps% 4000==0:\n",
        "                    with torch.no_grad():\n",
        "                        model.mode='test'\n",
        "                        auc=[]\n",
        "                        for i, (data, target) in enumerate(valid_loader):\n",
        "                            data = data.to(device)\n",
        "                            target = target.to(device)\n",
        "                            if model.reverse_complemet_mode:\n",
        "                                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                                for i in range(target_2.shape[0]):\n",
        "                                    target_2[i]=target[2*i]\n",
        "                                target=target_2.to(device)\n",
        "                            \n",
        "                            # Forward pass\n",
        "                            output = model(data)\n",
        "                            pred_sig=torch.sigmoid(output)\n",
        "                            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "                        model_auc[idx].append(np.mean(auc))\n",
        "                        print('Grid ', grid+1, ' with training fold ', idx+1, ' & learning steps ',learning_steps_list[len(model_auc[idx])-1], ' showed AUC of ' ,np.mean(auc))\n",
        "    \n",
        "    print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "    for n in range(5):\n",
        "        AUC=(model_auc[0][n]+model_auc[1][n]+model_auc[2][n])/3\n",
        "        if AUC>best_AUC:\n",
        "            best_AUC=AUC\n",
        "            best_learning_steps=learning_steps_list[n]\n",
        "            best_LearningRate=model.learning_rate\n",
        "            best_LearningMomentum=model.momentum_rate\n",
        "            best_neuType=model.neuType\n",
        "            best_poolType=model.poolType\n",
        "            best_sigmaConv=model.sigmaConv\n",
        "            best_dropprob=model.dropprob\n",
        "            best_sigmaNeu=model.sigmaNeu\n",
        "            best_beta1=model.beta1\n",
        "            best_beta2=model.beta2\n",
        "            best_beta3=model.beta3\n",
        "            at_grid = grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best pooling layer type =  maxavg\n",
            "best neural network type =  hidden\n",
            "best AUC =  0.8240904683876639\n",
            "best learning_steps =  8000\n",
            "best learning rate =  0.002637969772627659\n",
            "best momentum =  0.980116206722275\n",
            "best sigmaConv =  0.0007166743767315427\n",
            "best dropprob =  0.5\n",
            "best sigmaNeu =  0.004215769402742296\n",
            "best beta1 =  1.9910528029245976e-05\n",
            "best beta2 =  8.759637740128989e-09\n",
            "best beta3 =  6.745596095255953e-07\n"
          ]
        }
      ],
      "source": [
        "# Save The Best Hyperparameters\n",
        "\n",
        "print('best pooling layer type = ', best_poolType)\n",
        "print('best neural network type = ', best_neuType)\n",
        "print('best AUC = ', best_AUC)\n",
        "print('best learning_steps = ', best_learning_steps)\n",
        "print('best learning rate = ', best_LearningRate)\n",
        "print('best momentum = ', best_LearningMomentum)\n",
        "print('best sigmaConv = ', best_sigmaConv)\n",
        "print('best dropprob = ', best_dropprob)\n",
        "print('best sigmaNeu = ', best_sigmaNeu)\n",
        "print('best beta1 = ', best_beta1)\n",
        "print('best beta2 = ', best_beta2)\n",
        "print('best beta3 = ', best_beta3)\n",
        "\n",
        "hyperparameters = {'pool_type': best_poolType,\n",
        "                   'neu_type':best_neuType,\n",
        "                   'learning_steps':best_learning_steps,\n",
        "                   'learning_rate':best_LearningRate, \n",
        "                   'momentum':best_LearningMomentum,\n",
        "                   'sigmaConv':best_sigmaConv,\n",
        "                   'dropprob':best_dropprob,\n",
        "                   'sigmaNeu':best_sigmaNeu,\n",
        "                   'beta1':best_beta1, \n",
        "                   'beta2':best_beta2,\n",
        "                   'beta3':best_beta3}\n",
        "\n",
        "torch.save(hyperparameters, './Hyperparameters/' + name + '.pth') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "fkrEJTXuz8GW",
        "outputId": "cdc778fd-1557-47cd-bccb-7ffcc5ea8fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for model  1  =  0.9218317559924915  while best =  0\n",
            "AUC for model  2  =  0.9139176012386088  while best =  0.9218317559924915\n",
            "AUC for model  3  =  0.9240210308769735  while best =  0.9218317559924915\n",
            "AUC for model  4  =  0.921356071909896  while best =  0.9240210308769735\n",
            "AUC for model  5  =  0.9099033038923116  while best =  0.9240210308769735\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "best_AUC=0\n",
        "\n",
        "best_hyperparameters = torch.load('./Hyperparameters/' + name + '.pth')\n",
        "best_poolType=best_hyperparameters['pool_type']\n",
        "best_neuType=best_hyperparameters['neu_type']\n",
        "best_learning_steps=best_hyperparameters['learning_steps']\n",
        "best_LearningRate=best_hyperparameters['learning_rate']\n",
        "best_dropprob=best_hyperparameters['dropprob']\n",
        "best_LearningMomentum=best_hyperparameters['momentum']\n",
        "best_sigmaConv=best_hyperparameters['sigmaConv']\n",
        "best_sigmaNeu=best_hyperparameters['sigmaNeu']\n",
        "best_beta1=best_hyperparameters['beta1']\n",
        "best_beta2=best_hyperparameters['beta2']\n",
        "best_beta3=best_hyperparameters['beta3']\n",
        "\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "\n",
        "for model_number in range(num_training_model):\n",
        "\n",
        "    model = ConvNet_test(16,24,best_poolType,best_neuType,'training',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=False).to(device)\n",
        "\n",
        "    if model.neuType=='nohidden':\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "    train_loader=all_dataloader\n",
        "    valid_loader=all_dataloader\n",
        "    learning_steps=0\n",
        "\n",
        "    while learning_steps<=best_learning_steps:\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            \n",
        "            if model.neuType=='nohidden':\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "            else:\n",
        "                loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            learning_steps+=1\n",
        "            \n",
        "    with torch.no_grad():\n",
        "        model.mode='test'\n",
        "        auc=[]\n",
        "        for i, (data, target) in enumerate(valid_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            if model.reverse_complemet_mode:\n",
        "                target_2=torch.randn(int(target.shape[0]/2), 1)\n",
        "                for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                target=target_2.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            pred_sig=torch.sigmoid(output)\n",
        "            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "        AUC_training=np.mean(auc)\n",
        "        print('AUC for model ', model_number+1,' = ', AUC_training, ' while best = ', best_AUC)\n",
        "        if AUC_training > best_AUC:\n",
        "            state = {'conv': model.wConv,\n",
        "                     'rect':model.wRect,\n",
        "                     'wHidden':model.wHidden,\n",
        "                     'wHiddenBias':model.wHiddenBias,\n",
        "                     'wNeu':model.wNeu,\n",
        "                     'wNeuBias':model.wNeuBias}\n",
        "            torch.save(state, './Models/' + name + '.pth')\n",
        "            best_AUC = AUC_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "JetF0ajS4faT",
        "outputId": "a05ac166-fbef-4725-8a8d-221ab8c7e088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9240210308769735\n"
          ]
        }
      ],
      "source": [
        "# Training Performance\n",
        "\n",
        "checkpoint = torch.load('./Models/'+ name + '.pth')\n",
        "model = ConvNet_test(num_motif,motif_len,best_poolType,best_neuType,'test',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,device,reverse_complemet_mode=reverse_mode).to(device)\n",
        "model.wConv=checkpoint['conv']\n",
        "model.wRect=checkpoint['rect']\n",
        "model.wHidden=checkpoint['wHidden']\n",
        "model.wHiddenBias=checkpoint['wHiddenBias']\n",
        "model.wNeu=checkpoint['wNeu']\n",
        "model.wNeuBias=checkpoint['wNeuBias']\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(valid_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        if model.reverse_complemet_mode:\n",
        "          target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "          for i in range(target_2.shape[0]):\n",
        "            target_2[i]=target[2*i]\n",
        "          target=target_2.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred_sig=torch.sigmoid(output)\n",
        "        pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "              \n",
        "      AUC_training=np.mean(auc)\n",
        "      print(AUC_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "C4oqk1HnfQQw",
        "outputId": "d57c9cc3-de9f-4c97-f07d-31c2e5d9ea50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC on test data =  0.9132760000000001\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "\n",
        "test_loader = test_dataset_loader(test_dataset_path, motif_len)\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "          \n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #                         \n",
        "      AUC_test=np.mean(auc)\n",
        "      print('AUC on test data = ', AUC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AtHbPeAohR6m"
      },
      "outputs": [],
      "source": [
        "# write results\n",
        "\n",
        "with open(\"./results/AUC_training.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Train : \")\n",
        "    file.write(str(round(AUC_training, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()\n",
        "\n",
        "with open(\"./results/AUC_testing.txt\", \"a\") as file:\n",
        "    file.write('TF : ')\n",
        "    file.write(name)\n",
        "    file.write(\" - AUC Test : \")\n",
        "    file.write(str(round(AUC_test, 3)))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"---\"*20)\n",
        "    file.write(\"\\n\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepBind_colab_finale.ipynb",
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
